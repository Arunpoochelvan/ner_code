{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER Testing\n",
    "\n",
    "This code loads the spaCy and Flair trained models and use them to predict the named entities in given sentences; either reading from a file or by providing a sequence of sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spaCy\n",
    "\n",
    "In here we test the spaCy model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backend functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theses functions create training data suitable for the Spacy tool\n",
    "def _reformat_data(data):\n",
    "    for counter, example_ in enumerate(data):\n",
    "        index_ = 0\n",
    "        annotations = {}\n",
    "        sentence, ner_tag = example_\n",
    "        for word, tag in zip(sentence, ner_tag):\n",
    "            #-------------------------------------#\n",
    "            # analysing the NER tag\n",
    "            if '-' in tag:\n",
    "                In, tag = tag.split('-')\n",
    "                if tag not in annotations:\n",
    "                    annotations[tag] = []\n",
    "            else:\n",
    "                In = tag\n",
    "                \n",
    "            #-------------------------------------#\n",
    "            # creating the training data\n",
    "            if In == 'B':\n",
    "                annotations[tag].append([index_, index_+len(word)])\n",
    "            elif In == 'I':\n",
    "                annotations[tag][-1][1] = index_+len(word)\n",
    "            elif In != 'O':\n",
    "                print('=====!!!!!', In)\n",
    "                \n",
    "            index_ += len(word) + 1\n",
    "        \n",
    "        # fix the format\n",
    "        ann = {'entities':[ (val[0],val[1],key) for key in annotations for val in annotations[key]]}\n",
    "            \n",
    "        ## update the training data to fit spacy format\n",
    "        text = ' '.join(sentence)\n",
    "        data[counter] = (text, ann)\n",
    "    return data\n",
    "\n",
    "def _create_training_data(raw_data):\n",
    "    File_ = open(raw_data, 'r')\n",
    "    TRAIN_DATA = []\n",
    "    sentence = []\n",
    "    ner_tag = []\n",
    "\n",
    "    for line in File_:\n",
    "        try:\n",
    "            line = line.split('\\n')[0]\n",
    "\n",
    "            if line == '':\n",
    "                TRAIN_DATA.append([sentence,ner_tag])\n",
    "                sentence = []\n",
    "                ner_tag = []\n",
    "            else:\n",
    "                word, POS1, CNK2, tag = line.split(' ')\n",
    "                sentence.append(word)\n",
    "                ner_tag.append(tag)\n",
    "        except:\n",
    "            print('you have a bad line..',line)\n",
    "            \n",
    "    File_.close()\n",
    "    return _reformat_data(TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_texts(texts):\n",
    "    colors = {}\n",
    "    colors['ORG'] = 'orange'\n",
    "    colors['PER'] = '#aa9cfc'\n",
    "    colors['LOC'] = 'green'\n",
    "    colors['MISC'] = 'yellow'\n",
    "    options = {'ents': ['ORG', 'PER', 'LOC', 'MISC'], 'colors': colors}\n",
    "\n",
    "    for text in texts:\n",
    "        doc = nlp(text)\n",
    "        Entities = [(ent.text, ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n",
    "        if len(Entities) > 0:\n",
    "            displacy.render(doc, style='ent', jupyter=True, options=options)\n",
    "        else:\n",
    "            print('no entities detected: ',text)\n",
    "        print('--------------------------')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_test_set(filepath):\n",
    "    ext = filepath.split('.')[-1]\n",
    "    if ext == 'json':\n",
    "        VAL_DATA = json.load(open(filepath,'r'))\n",
    "    elif ext == 'txt':\n",
    "        VAL_DATA = _create_training_data(filepath) \n",
    "    else:\n",
    "        VAL_DATA = []\n",
    "\n",
    "    TP, FN, FP = 0, 0, 0 # True positives, False negatives, False Positives\n",
    "    for text, ann in VAL_DATA:\n",
    "        doc = nlp(text)\n",
    "        GT = sorted(ann['entities'], key=lambda tup: tup[0])\n",
    "        Entities = [(ent.text, ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n",
    "        Ground_Truth = [(text[a[0]:a[1]], a[0], a[1], a[2]) for a in GT]\n",
    "        \n",
    "        TP += len([value for value in Entities if value in Ground_Truth])\n",
    "        FP += len([value for value in Entities if value not in Ground_Truth])\n",
    "        FN += len([value for value in Ground_Truth if value not in Entities])\n",
    "    Pr, Re = TP/(TP+FP), TP/(TP+FN) ## computing Precision and Recall\n",
    "    print('  -Validation: -precision=%.3f -recall=%.3f -f1 score=%.3f'  % (Pr, Re, 2*(Pr*Re)/(Pr+Re)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model 'Spacy/'\n"
     ]
    }
   ],
   "source": [
    "## load the spaCy model\n",
    "model = 'Spacy/'\n",
    "\n",
    "\"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n",
    "try:\n",
    "    nlp = spacy.load(model)  # load existing spaCy model\n",
    "    print(\"Loaded model '%s'\" % model)\n",
    "except:\n",
    "    print(\"Could not find the model, please check you have the model in your directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reading from a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -Validation: -precision=0.990 -recall=0.991 -f1 score=0.991\n"
     ]
    }
   ],
   "source": [
    "# To test the model on a txt file use:\n",
    "predict_on_test_set('Dataset/ner_dataset_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence of sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: green; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    New York\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " city</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: orange; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Muhannad Alomari\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " is going to \n",
       "<mark class=\"entity\" style=\"background: green; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    New York\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To test the model with a sequence of sentences use:\n",
    "predict_on_texts(['New York city', 'Muhannad Alomari is going to New York.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flair model\n",
    "\n",
    "In here we test the Flair model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backend functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_texts_flair(texts):\n",
    "    for text in texts:\n",
    "        sentence = Sentence(text)\n",
    "        \n",
    "        # predict NER tags\n",
    "        flair_model.predict(sentence)\n",
    "\n",
    "        # print sentence with predicted tags\n",
    "        print(sentence.to_tagged_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_test_set_flair(filepath):\n",
    "    ext = filepath.split('.')[-1]\n",
    "    if ext == 'txt':\n",
    "        VAL_DATA = _create_training_data(filepath) \n",
    "    else:\n",
    "        VAL_DATA = []\n",
    "\n",
    "    TP, FN, FP = 0, 0, 0 # True positives, False negatives, False Positives\n",
    "    for text, ann in VAL_DATA:\n",
    "        sentence = Sentence(text)\n",
    "        \n",
    "        # predict NER tags\n",
    "        flair_model.predict(sentence)\n",
    "\n",
    "        # print sentence with predicted tags\n",
    "        sent = sentence.to_tagged_string()\n",
    "        \n",
    "        Entities = [(entity.start_pos, entity.end_pos, entity.tag) for entity in sentence.get_spans('ner')]\n",
    "        Ground_Truth = sorted(ann['entities'], key=lambda tup: tup[0])\n",
    "        \n",
    "        TP += len([value for value in Entities if value in Ground_Truth])\n",
    "        FP += len([value for value in Entities if value not in Ground_Truth])\n",
    "        FN += len([value for value in Ground_Truth if value not in Entities])\n",
    "    Pr, Re = TP/(TP+FP), TP/(TP+FN) ## computing Precision and Recall\n",
    "    print('  -Validation: -precision=%.3f -recall=%.3f -f1 score=%.3f'  % (Pr, Re, 2*(Pr*Re)/(Pr+Re)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Flair model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model\n",
    "flair_model: SequenceTagger = SequenceTagger.load_from_file('Flair/final-model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading from a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-29 06:01:34,773 Ignore 1 sentence(s) with no tokens.\n",
      "  -Validation: -precision=0.963 -recall=0.945 -f1 score=0.954\n"
     ]
    }
   ],
   "source": [
    "predict_on_test_set_flair('Dataset/ner_dataset_test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequences of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muhannad <B-PER> Alomari <I-PER> is going to New York.\n"
     ]
    }
   ],
   "source": [
    "predict_on_texts_flair(['Muhannad Alomari is going to New York.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
