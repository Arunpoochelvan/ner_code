{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will attempt to do the Named Entity Recognition task. I will train two models and demonstrate their results below.\n",
    "\n",
    "The models are:<br>\n",
    "1- spaCy NER Gold Parse system [1]. spaCy is an industrial strength NLP library that is widely used by large corporation to handle similar NLP applications. E.g. it's being used by BBC, Microsoft, and many other big companies.\n",
    "\n",
    "2- Flair embeddings [2]. Contextual String Embeddings for Sequence Labeling is currently the state-of-the-art [3] system in Named Enitiy Recognition task, and the only system outperforming Google's BERT [4] model. More information on Flair can be found on their paper [5].\n",
    "\n",
    "I have selected these two models to demonstrate that I am capable of providing a quick & relaiable solution when needed (spaCy). Also, when time/resource allows, I am capable of providing a siginfacntly better solution that is considered the state-of-the-art in the field of NLP (Flair embeddings).\n",
    "\n",
    "spaCy needs a couple of hours to train a decent model on a potato laptop, while Flair embeddings (with CharLMEmbeddings) can take a couple of days on a proper workstation with GPUs. \n",
    "\n",
    "Requirements to run this code:\n",
    "- python 3.6\n",
    "- spacy '2.0.16'\n",
    "- flair\n",
    "\n",
    "[1] https://spacy.io/<br>\n",
    "[2] https://github.com/zalandoresearch/flair<br>\n",
    "[3] https://github.com/zalandoresearch/flair#comparison-with-state-of-the-art<br>\n",
    "[4] https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html<br>\n",
    "[5] https://drive.google.com/file/d/17yVpFA7MmXaQFTe-HDpZuqw9fJlmzg56/view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "from pathlib import Path\n",
    "from spacy import displacy\n",
    "import json\n",
    "import random\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import SequenceTaggerTrainer\n",
    "from flair.data import TaggedCorpus\n",
    "from flair.data_fetcher import NLPTaskDataFetcher, NLPTask\n",
    "from flair.embeddings import TokenEmbeddings, WordEmbeddings, StackedEmbeddings, CharLMEmbeddings, CharacterEmbeddings\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training, Validation, Testing\n",
    "\n",
    "In here we divide the provided training data into 3 parts; training (80%), validation (10%) and testing (10%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  *Training has ( 14760 ) instances.\n",
      "  *Validation has ( 1845 ) instances.\n",
      "  *TEST has ( 1849 ) instances.\n"
     ]
    }
   ],
   "source": [
    "# reading the raw data\n",
    "raw_data_PATH = 'Dataset/'\n",
    "File_ = open(raw_data_PATH+'ner_dataset.txt')\n",
    "\n",
    "DATA = []\n",
    "sentence = []\n",
    "\n",
    "for line in File_:\n",
    "    try:\n",
    "        if line == '\\n':\n",
    "            DATA.append(sentence)\n",
    "            sentence = []\n",
    "        else:\n",
    "            sentence.append(line)\n",
    "    except:\n",
    "        print('you have a bad line..',line)\n",
    "\n",
    "random.shuffle(DATA)    # shuffling the data is always good to preven overfitting\n",
    "\n",
    "# dividing the data into trainig (80%), validation (10%) and testing (10%).\n",
    "split_ = int(0.1 * len(DATA))\n",
    "TRAIN_DATA, VAL_DATA, TEST_DATA = DATA[:8*split_], DATA[8*split_:9*split_], DATA[9*split_:]\n",
    "print('  *Training has (',len(TRAIN_DATA),') instances.')\n",
    "print('  *Validation has (',len(VAL_DATA),') instances.')\n",
    "print('  *TEST has (',len(TEST_DATA),') instances.')\n",
    "\n",
    "# print()\n",
    "# storing the data\n",
    "for name,data in zip(['training','validation','test'],[TRAIN_DATA, VAL_DATA, TEST_DATA]):\n",
    "    F = open(raw_data_PATH+'ner_dataset_'+name+'.txt','w')\n",
    "    F.write('\\n'.join([''.join(x) for x in TRAIN_DATA]))\n",
    "    F.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- spaCy NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data for spacy\n",
    "\n",
    "Inspecting the data, shuffeling it and preparing it to be fed into the Spacy model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theses functions create training data suitable for the Spacy tool\n",
    "def _reformat_data(data):\n",
    "    for counter, example_ in enumerate(data):\n",
    "        index_ = 0\n",
    "        annotations = {}\n",
    "        sentence, ner_tag = example_\n",
    "        for word, tag in zip(sentence, ner_tag):\n",
    "            #-------------------------------------#\n",
    "            # analysing the NER tag\n",
    "            if '-' in tag:\n",
    "                In, tag = tag.split('-')\n",
    "                if tag not in annotations:\n",
    "                    annotations[tag] = []\n",
    "            else:\n",
    "                In = tag\n",
    "                \n",
    "            #-------------------------------------#\n",
    "            # creating the training data\n",
    "            if In == 'B':\n",
    "                annotations[tag].append([index_, index_+len(word)])\n",
    "            elif In == 'I':\n",
    "                annotations[tag][-1][1] = index_+len(word)\n",
    "            elif In != 'O':\n",
    "                print('=====!!!!!', In)\n",
    "                \n",
    "            index_ += len(word) + 1\n",
    "        \n",
    "        # fix the format\n",
    "        ann = {'entities':[ (val[0],val[1],key) for key in annotations for val in annotations[key]]}\n",
    "            \n",
    "        ## update the training data to fit spacy format\n",
    "        text = ' '.join(sentence)\n",
    "        data[counter] = (text, ann)\n",
    "    return data\n",
    "\n",
    "def _create_training_data(raw_data):\n",
    "    File_ = open(raw_data, 'r')\n",
    "    TRAIN_DATA = []\n",
    "    sentence = []\n",
    "    ner_tag = []\n",
    "\n",
    "    for line in File_:\n",
    "        try:\n",
    "            line = line.split('\\n')[0]\n",
    "\n",
    "            if line == '':\n",
    "                TRAIN_DATA.append([sentence,ner_tag])\n",
    "                sentence = []\n",
    "                ner_tag = []\n",
    "            else:\n",
    "                word, POS1, CNK2, tag = line.split(' ')\n",
    "                sentence.append(word)\n",
    "                ner_tag.append(tag)\n",
    "        except:\n",
    "            print('you have a bad line..',line)\n",
    "            \n",
    "    File_.close()\n",
    "    return _reformat_data(TRAIN_DATA)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a total of 14759 training instances.\n",
      "We have 4 classes in this dataset. {'LOC', 'MISC', 'PER', 'ORG'}\n",
      "  -class( LOC ) has 7171 instances.\n",
      "  -class( MISC ) has 3478 instances.\n",
      "  -class( PER ) has 6852 instances.\n",
      "  -class( ORG ) has 6126 instances.\n"
     ]
    }
   ],
   "source": [
    "# reading the raw data\n",
    "raw_data_PATH = 'Dataset/'\n",
    "\n",
    "# prepare the training data into spacy format\n",
    "TRAIN_DATA = _create_training_data(raw_data_PATH+'ner_dataset_training.txt')\n",
    "VAL_DATA = _create_training_data(raw_data_PATH+'ner_dataset_validation.txt')\n",
    "TEST_DATA = _create_training_data(raw_data_PATH+'ner_dataset_test.txt')\n",
    "\n",
    "# Inspecting the data        \n",
    "print('We have a total of',len(TRAIN_DATA),'training instances.')\n",
    "\n",
    "# print class analysis\n",
    "all_tags = [ent[2] for data in TRAIN_DATA for ent in data[1]['entities']]\n",
    "classes = set(all_tags)\n",
    "print('We have',len(classes),'classes in this dataset.',classes)\n",
    "\n",
    "for c_ in classes:\n",
    "    print('  -class(',c_,') has',all_tags.count(c_),'instances.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not find the model, Created a blank 'en' model isntead\n"
     ]
    }
   ],
   "source": [
    "# Load or create a blank English model\n",
    "model = 'Spacy/'\n",
    "output_dir = 'Spacy/'\n",
    "\n",
    "if output_dir is not None:\n",
    "    output_dir = Path(output_dir)\n",
    "    if not output_dir.exists():\n",
    "        output_dir.mkdir()\n",
    "        \n",
    "\n",
    "\"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n",
    "if model is not None:\n",
    "    try:\n",
    "        nlp = spacy.load(model)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    except:\n",
    "        nlp = spacy.blank('en')  # create blank Language class\n",
    "        print(\"Could not find the model, Created a blank 'en' model isntead\")\n",
    "else:\n",
    "    nlp = spacy.blank('en')  # create blank Language class\n",
    "    print(\"Created blank 'en' model\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_texts(texts):\n",
    "    colors = {}\n",
    "    colors['ORG'] = 'orange'\n",
    "    colors['PER'] = '#aa9cfc'\n",
    "    colors['LOC'] = 'green'\n",
    "    colors['MISC'] = 'yellow'\n",
    "    options = {'ents': classes, 'colors': colors}\n",
    "\n",
    "    for text in texts:\n",
    "        doc = nlp(text)\n",
    "        Entities = [(ent.text, ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n",
    "        if len(Entities) > 0:\n",
    "            displacy.render(doc, style='ent', jupyter=True, options=options)\n",
    "        else:\n",
    "            print('no entities detected: ',text)\n",
    "        print('--------------------------')\n",
    "        print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_on_test_set(filepath):\n",
    "    ext = filepath.split('.')[-1]\n",
    "    if ext == 'txt':\n",
    "        VAL_DATA = _create_training_data(filepath) \n",
    "    else:\n",
    "        VAL_DATA = []\n",
    "\n",
    "    TP, FN, FP = 0, 0, 0 # True positives, False negatives, False Positives\n",
    "    for text, ann in VAL_DATA:\n",
    "        doc = nlp(text)\n",
    "        GT = sorted(ann['entities'], key=lambda tup: tup[0])\n",
    "        Entities = [(ent.text, ent.start_char, ent.end_char, ent.label_) for ent in doc.ents]\n",
    "        Ground_Truth = [(text[a[0]:a[1]], a[0], a[1], a[2]) for a in GT]\n",
    "        \n",
    "        TP += len([value for value in Entities if value in Ground_Truth])\n",
    "        FP += len([value for value in Entities if value not in Ground_Truth])\n",
    "        FN += len([value for value in Ground_Truth if value not in Entities])\n",
    "    Pr, Re = TP/(TP+FP), TP/(TP+FN) ## computing Precision and Recall\n",
    "    print('  -Validation: -precision=%.3f -recall=%.3f -f1 score=%.3f'  % (Pr, Re, 2*(Pr*Re)/(Pr+Re)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "n_iter = 20 # number of iteration\n",
    "                \n",
    "# create the built-in pipeline components and add them to the pipeline\n",
    "# nlp.create_pipe works for built-ins that are registered with spaCy\n",
    "if 'ner' not in nlp.pipe_names:\n",
    "    ner = nlp.create_pipe('ner')\n",
    "    nlp.add_pipe(ner, last=True)\n",
    "# otherwise, get it so we can add labels\n",
    "else:\n",
    "    ner = nlp.get_pipe('ner')\n",
    "    \n",
    "# add labels to model\n",
    "for ent in classes:\n",
    "    ner.add_label(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unnamed vectors -- this won't allow multiple vectors models to be loaded. (Shape: (0, 0))\n",
      "*started trianing..\n",
      "  -Trainnig loss {'ner': 535.5363936112482}\n",
      "  -Validation: -precision=0.752 -recall=0.783 -f1 score=0.768\n",
      "Saved model to Spacy\n",
      "  -Trainnig loss {'ner': 187.14779767257355}\n",
      "  -Validation: -precision=0.882 -recall=0.897 -f1 score=0.890\n",
      "Saved model to Spacy\n",
      "  -Trainnig loss {'ner': 134.02237596263717}\n",
      "  -Validation: -precision=0.925 -recall=0.937 -f1 score=0.930\n",
      "Saved model to Spacy\n",
      "  -Trainnig loss {'ner': 108.67592926707505}\n",
      "  -Validation: -precision=0.938 -recall=0.949 -f1 score=0.943\n",
      "Saved model to Spacy\n",
      "  -Trainnig loss {'ner': 84.78177396119163}\n",
      "  -Validation: -precision=0.946 -recall=0.952 -f1 score=0.949\n",
      "Saved model to Spacy\n",
      "  -Trainnig loss {'ner': 78.67414079785877}\n",
      "  -Validation: -precision=0.956 -recall=0.964 -f1 score=0.960\n",
      "Saved model to Spacy\n",
      "  -Trainnig loss {'ner': 70.96298747111538}\n",
      "  -Validation: -precision=0.966 -recall=0.971 -f1 score=0.969\n",
      "Saved model to Spacy\n",
      "  -Trainnig loss {'ner': 62.735257567765636}\n",
      "  -Validation: -precision=0.967 -recall=0.974 -f1 score=0.971\n",
      "Saved model to Spacy\n",
      "  -Trainnig loss {'ner': 61.778459966365396}\n",
      "  -Validation: -precision=0.969 -recall=0.977 -f1 score=0.973\n",
      "Saved model to Spacy\n",
      "  -Trainnig loss {'ner': 53.09174002041394}\n",
      "  -Validation: -precision=0.974 -recall=0.979 -f1 score=0.977\n",
      "Saved model to Spacy\n",
      "  -Trainnig loss {'ner': 48.46963288918163}\n",
      "  -Validation: -precision=0.979 -recall=0.983 -f1 score=0.981\n",
      "Saved model to Spacy\n",
      "  -Trainnig loss {'ner': 47.77794483506641}\n",
      "  -Validation: -precision=0.980 -recall=0.984 -f1 score=0.982\n",
      "Saved model to Spacy\n",
      "  -Trainnig loss {'ner': 42.40223939781551}\n",
      "  -Validation: -precision=0.984 -recall=0.986 -f1 score=0.985\n",
      "Saved model to Spacy\n",
      "  -Trainnig loss {'ner': 40.96762497226011}\n",
      "  -Validation: -precision=0.985 -recall=0.987 -f1 score=0.986\n",
      "Saved model to Spacy\n",
      "  -Trainnig loss {'ner': 40.42088799942401}\n",
      "  -Validation: -precision=0.988 -recall=0.987 -f1 score=0.988\n",
      "Saved model to Spacy\n",
      "  -Trainnig loss {'ner': 37.15101254935841}\n",
      "  -Validation: -precision=0.989 -recall=0.990 -f1 score=0.989\n",
      "Saved model to Spacy\n",
      "  -Trainnig loss {'ner': 32.80888440195675}\n",
      "  -Validation: -precision=0.989 -recall=0.992 -f1 score=0.990\n",
      "Saved model to Spacy\n",
      "  -Trainnig loss {'ner': 31.82983549849966}\n",
      "  -Validation: -precision=0.988 -recall=0.991 -f1 score=0.989\n",
      "Saved model to Spacy\n",
      "  -Trainnig loss {'ner': 34.657070057214575}\n",
      "  -Validation: -precision=0.990 -recall=0.992 -f1 score=0.991\n",
      "Saved model to Spacy\n",
      "  -Trainnig loss {'ner': 32.363908509656184}\n",
      "  -Validation: -precision=0.990 -recall=0.991 -f1 score=0.991\n",
      "Saved model to Spacy\n"
     ]
    }
   ],
   "source": [
    "# get names of other pipes to disable them during training\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "    optimizer = nlp.begin_training()\n",
    "    print('*started trianing..')\n",
    "    for itn in range(n_iter):\n",
    "        # shuffle the data (reduce the overfitting of the model)\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        # batch up the examples using spaCy's minibatch\n",
    "        batches = minibatch(TRAIN_DATA, size=compounding(4., 32., 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(\n",
    "                texts,  # batch of texts\n",
    "                annotations,  # batch of annotations\n",
    "                drop=0.5,  # dropout - make it harder to memorise data\n",
    "                sgd=optimizer,  # callable to update weights\n",
    "                losses=losses)\n",
    "        ## printing training and validation losses\n",
    "        print('  -Trainnig loss', losses)\n",
    "        predict_on_test_set(raw_data_PATH+'ner_dataset_validation.txt')\n",
    "        \n",
    "        # save model to output directory\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\", output_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: green; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    New York\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " city</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">My name is \n",
       "<mark class=\"entity\" style=\"background: green; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Muhannad\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", and I live in the \n",
       "<mark class=\"entity\" style=\"background: green; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    US\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ". I work in \n",
       "<mark class=\"entity\" style=\"background: green; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Rolls Royce\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ".</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To test the model on a txt file use:\n",
    "# predict_on_test_set(raw_data_PATH+'ner_dataset.txt')\n",
    "\n",
    "# To test the model with a sequence of sentences use:\n",
    "predict_on_texts(['New York city','My name is Muhannad, and I live in the US. I work in Rolls Royce.'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no entities detected:  and we will deal with such designs sternly , \" the prime minister said .\n",
      "--------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: orange; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Hansa Rostock\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " 3 0 2 1 3 4 2</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">\n",
       "<mark class=\"entity\" style=\"background: yellow; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Russian\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " peacemaker \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Alexander Lebed\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " said he and rebel military leader \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Aslan Maskhadov\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " agreed after overnight talks to defer the decision on whether \n",
       "<mark class=\"entity\" style=\"background: green; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Chechnya\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " should be independent until December 31 , 2001 .</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5\">Interior Minister \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    Manfred Kanther\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " said in a statement he \" welcomed the prosecution and conviction of one of the ringleaders of international \n",
       "<mark class=\"entity\" style=\"background: yellow; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
       "    neo-Nazism\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       " and biggest distributers of vicious racist publications \" .</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Plotting the NER tags.\n",
    "# using display-spacy to show the ner values (showing a sample only).\n",
    "random_examples = [int(random.random()*len(VAL_DATA)) for i in range(4)]\n",
    "texts = [VAL_DATA[ex][0] for ex in random_examples]\n",
    "predict_on_texts(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flair model\n",
    "\n",
    "Flair includes word embeddings to predict the named entites within the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'<unk>', b'O', b'B-PER', b'I-PER', b'B-LOC', b'B-ORG', b'I-ORG', b'B-MISC', b'I-MISC', b'I-LOC', b'<START>', b'<STOP>']\n",
      "2018-11-29 01:00:01,795 Evaluation method: F1\n",
      "2018-11-29 01:00:01,798 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:00:02,021 epoch 1 - iter 0/462 - loss 34.05309677\n",
      "2018-11-29 01:00:12,215 epoch 1 - iter 46/462 - loss 10.13411792\n",
      "2018-11-29 01:00:23,134 epoch 1 - iter 92/462 - loss 8.46139271\n",
      "2018-11-29 01:00:34,241 epoch 1 - iter 138/462 - loss 7.50607529\n",
      "2018-11-29 01:00:46,656 epoch 1 - iter 184/462 - loss 6.87369085\n",
      "2018-11-29 01:00:57,415 epoch 1 - iter 230/462 - loss 6.40932856\n",
      "2018-11-29 01:01:08,262 epoch 1 - iter 276/462 - loss 6.07861754\n",
      "2018-11-29 01:01:19,153 epoch 1 - iter 322/462 - loss 5.81194002\n",
      "2018-11-29 01:01:30,470 epoch 1 - iter 368/462 - loss 5.53879106\n",
      "2018-11-29 01:01:41,213 epoch 1 - iter 414/462 - loss 5.33879499\n",
      "2018-11-29 01:01:52,256 epoch 1 - iter 460/462 - loss 5.15535993\n",
      "2018-11-29 01:01:52,405 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:03:14,927 EPOCH 1: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 01:03:14,928 DEV : f-score 0.7236 - acc 0.7236 - tp 14977 - fp 2793 - fn 8650 - tn 14977\n",
      "2018-11-29 01:03:14,928 TEST: f-score 0.7236 - acc 0.7236 - tp 14977 - fp 2793 - fn 8650 - tn 14977\n",
      "2018-11-29 01:03:14,939 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:03:15,161 epoch 2 - iter 0/462 - loss 3.39187717\n",
      "2018-11-29 01:03:24,596 epoch 2 - iter 46/462 - loss 3.60287063\n",
      "2018-11-29 01:03:33,718 epoch 2 - iter 92/462 - loss 3.47623133\n",
      "2018-11-29 01:03:43,441 epoch 2 - iter 138/462 - loss 3.43314939\n",
      "2018-11-29 01:03:52,876 epoch 2 - iter 184/462 - loss 3.37872986\n",
      "2018-11-29 01:04:02,361 epoch 2 - iter 230/462 - loss 3.29988379\n",
      "2018-11-29 01:04:11,736 epoch 2 - iter 276/462 - loss 3.24725884\n",
      "2018-11-29 01:04:21,667 epoch 2 - iter 322/462 - loss 3.22886804\n",
      "2018-11-29 01:04:31,087 epoch 2 - iter 368/462 - loss 3.18350820\n",
      "2018-11-29 01:04:40,560 epoch 2 - iter 414/462 - loss 3.15129154\n",
      "2018-11-29 01:04:49,518 epoch 2 - iter 460/462 - loss 3.10504262\n",
      "2018-11-29 01:04:49,598 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:06:06,601 EPOCH 2: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 01:06:06,602 DEV : f-score 0.8011 - acc 0.8011 - tp 17636 - fp 2767 - fn 5991 - tn 17636\n",
      "2018-11-29 01:06:06,603 TEST: f-score 0.8011 - acc 0.8011 - tp 17636 - fp 2767 - fn 5991 - tn 17636\n",
      "2018-11-29 01:06:06,604 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:06:06,795 epoch 3 - iter 0/462 - loss 2.05355263\n",
      "2018-11-29 01:06:16,142 epoch 3 - iter 46/462 - loss 2.72575770\n",
      "2018-11-29 01:06:25,308 epoch 3 - iter 92/462 - loss 2.69325288\n",
      "2018-11-29 01:06:35,272 epoch 3 - iter 138/462 - loss 2.73655442\n",
      "2018-11-29 01:06:44,588 epoch 3 - iter 184/462 - loss 2.70899826\n",
      "2018-11-29 01:06:55,278 epoch 3 - iter 230/462 - loss 2.73055800\n",
      "2018-11-29 01:07:06,247 epoch 3 - iter 276/462 - loss 2.73948363\n",
      "2018-11-29 01:07:15,991 epoch 3 - iter 322/462 - loss 2.70421786\n",
      "2018-11-29 01:07:25,624 epoch 3 - iter 368/462 - loss 2.70864244\n",
      "2018-11-29 01:07:34,779 epoch 3 - iter 414/462 - loss 2.69650178\n",
      "2018-11-29 01:07:43,883 epoch 3 - iter 460/462 - loss 2.67722062\n",
      "2018-11-29 01:07:44,017 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:09:01,420 EPOCH 3: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 01:09:01,421 DEV : f-score 0.8225 - acc 0.8225 - tp 18187 - fp 2409 - fn 5440 - tn 18187\n",
      "2018-11-29 01:09:01,421 TEST: f-score 0.8225 - acc 0.8225 - tp 18187 - fp 2409 - fn 5440 - tn 18187\n",
      "2018-11-29 01:09:01,422 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:09:01,662 epoch 4 - iter 0/462 - loss 2.12142253\n",
      "2018-11-29 01:09:12,252 epoch 4 - iter 46/462 - loss 2.38257910\n",
      "2018-11-29 01:09:23,527 epoch 4 - iter 92/462 - loss 2.40936858\n",
      "2018-11-29 01:09:34,342 epoch 4 - iter 138/462 - loss 2.45366149\n",
      "2018-11-29 01:09:44,693 epoch 4 - iter 184/462 - loss 2.45995447\n",
      "2018-11-29 01:09:55,388 epoch 4 - iter 230/462 - loss 2.46886833\n",
      "2018-11-29 01:10:04,710 epoch 4 - iter 276/462 - loss 2.48251756\n",
      "2018-11-29 01:10:14,727 epoch 4 - iter 322/462 - loss 2.46755316\n",
      "2018-11-29 01:10:24,172 epoch 4 - iter 368/462 - loss 2.50868374\n",
      "2018-11-29 01:10:33,915 epoch 4 - iter 414/462 - loss 2.51762281\n",
      "2018-11-29 01:10:43,109 epoch 4 - iter 460/462 - loss 2.50138949\n",
      "2018-11-29 01:10:43,256 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:12:01,294 EPOCH 4: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 01:12:01,295 DEV : f-score 0.8374 - acc 0.8374 - tp 18928 - fp 2650 - fn 4699 - tn 18928\n",
      "2018-11-29 01:12:01,295 TEST: f-score 0.8374 - acc 0.8374 - tp 18928 - fp 2650 - fn 4699 - tn 18928\n",
      "2018-11-29 01:12:01,296 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:12:01,520 epoch 5 - iter 0/462 - loss 2.34537268\n",
      "2018-11-29 01:12:10,886 epoch 5 - iter 46/462 - loss 2.40571915\n",
      "2018-11-29 01:12:20,176 epoch 5 - iter 92/462 - loss 2.37827128\n",
      "2018-11-29 01:12:29,658 epoch 5 - iter 138/462 - loss 2.40107588\n",
      "2018-11-29 01:12:39,300 epoch 5 - iter 184/462 - loss 2.42330170\n",
      "2018-11-29 01:12:48,642 epoch 5 - iter 230/462 - loss 2.42104895\n",
      "2018-11-29 01:12:58,431 epoch 5 - iter 276/462 - loss 2.42155793\n",
      "2018-11-29 01:13:07,505 epoch 5 - iter 322/462 - loss 2.41096825\n",
      "2018-11-29 01:13:16,757 epoch 5 - iter 368/462 - loss 2.38471698\n",
      "2018-11-29 01:13:26,224 epoch 5 - iter 414/462 - loss 2.36952005\n",
      "2018-11-29 01:13:35,322 epoch 5 - iter 460/462 - loss 2.35375362\n",
      "2018-11-29 01:13:35,413 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:14:52,559 EPOCH 5: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 01:14:52,560 DEV : f-score 0.8540 - acc 0.8539 - tp 19272 - fp 2238 - fn 4355 - tn 19272\n",
      "2018-11-29 01:14:52,561 TEST: f-score 0.8540 - acc 0.8539 - tp 19272 - fp 2238 - fn 4355 - tn 19272\n",
      "2018-11-29 01:14:52,561 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:14:52,758 epoch 6 - iter 0/462 - loss 1.50107682\n",
      "2018-11-29 01:15:02,513 epoch 6 - iter 46/462 - loss 2.11048390\n",
      "2018-11-29 01:15:12,652 epoch 6 - iter 92/462 - loss 2.16775239\n",
      "2018-11-29 01:15:21,972 epoch 6 - iter 138/462 - loss 2.16615263\n",
      "2018-11-29 01:15:31,670 epoch 6 - iter 184/462 - loss 2.23122872\n",
      "2018-11-29 01:15:40,964 epoch 6 - iter 230/462 - loss 2.22190433\n",
      "2018-11-29 01:15:50,523 epoch 6 - iter 276/462 - loss 2.22927661\n",
      "2018-11-29 01:16:00,959 epoch 6 - iter 322/462 - loss 2.21054096\n",
      "2018-11-29 01:16:11,421 epoch 6 - iter 368/462 - loss 2.22396510\n",
      "2018-11-29 01:16:22,051 epoch 6 - iter 414/462 - loss 2.22925408\n",
      "2018-11-29 01:16:32,872 epoch 6 - iter 460/462 - loss 2.20476825\n",
      "2018-11-29 01:16:32,952 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:17:50,002 EPOCH 6: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 01:17:50,002 DEV : f-score 0.8419 - acc 0.8419 - tp 18441 - fp 1738 - fn 5186 - tn 18441\n",
      "2018-11-29 01:17:50,003 TEST: f-score 0.8419 - acc 0.8419 - tp 18441 - fp 1738 - fn 5186 - tn 18441\n",
      "2018-11-29 01:17:50,005 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:17:50,236 epoch 7 - iter 0/462 - loss 2.24434638\n",
      "2018-11-29 01:18:01,087 epoch 7 - iter 46/462 - loss 2.06873273\n",
      "2018-11-29 01:18:12,114 epoch 7 - iter 92/462 - loss 2.16269617\n",
      "2018-11-29 01:18:22,657 epoch 7 - iter 138/462 - loss 2.11609528\n",
      "2018-11-29 01:18:33,430 epoch 7 - iter 184/462 - loss 2.17537983\n",
      "2018-11-29 01:18:43,861 epoch 7 - iter 230/462 - loss 2.19074355\n",
      "2018-11-29 01:18:54,163 epoch 7 - iter 276/462 - loss 2.19823973\n",
      "2018-11-29 01:19:05,450 epoch 7 - iter 322/462 - loss 2.20156076\n",
      "2018-11-29 01:19:15,697 epoch 7 - iter 368/462 - loss 2.18191295\n",
      "2018-11-29 01:19:26,863 epoch 7 - iter 414/462 - loss 2.15953857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-29 01:19:37,688 epoch 7 - iter 460/462 - loss 2.15468833\n",
      "2018-11-29 01:19:37,806 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:20:55,205 EPOCH 7: lr 0.1000 - bad epochs 1\n",
      "2018-11-29 01:20:55,206 DEV : f-score 0.8705 - acc 0.8705 - tp 19779 - fp 2037 - fn 3848 - tn 19779\n",
      "2018-11-29 01:20:55,206 TEST: f-score 0.8705 - acc 0.8705 - tp 19779 - fp 2037 - fn 3848 - tn 19779\n",
      "2018-11-29 01:20:55,207 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:20:55,471 epoch 8 - iter 0/462 - loss 1.42024136\n",
      "2018-11-29 01:21:05,252 epoch 8 - iter 46/462 - loss 1.96299510\n",
      "2018-11-29 01:21:14,765 epoch 8 - iter 92/462 - loss 2.07168673\n",
      "2018-11-29 01:21:24,358 epoch 8 - iter 138/462 - loss 2.14242340\n",
      "2018-11-29 01:21:33,943 epoch 8 - iter 184/462 - loss 2.11860722\n",
      "2018-11-29 01:21:42,894 epoch 8 - iter 230/462 - loss 2.08180723\n",
      "2018-11-29 01:21:53,323 epoch 8 - iter 276/462 - loss 2.10719491\n",
      "2018-11-29 01:22:04,245 epoch 8 - iter 322/462 - loss 2.08851708\n",
      "2018-11-29 01:22:14,663 epoch 8 - iter 368/462 - loss 2.06806348\n",
      "2018-11-29 01:22:24,815 epoch 8 - iter 414/462 - loss 2.06512926\n",
      "2018-11-29 01:22:34,052 epoch 8 - iter 460/462 - loss 2.07740791\n",
      "2018-11-29 01:22:34,175 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:23:51,678 EPOCH 8: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 01:23:51,678 DEV : f-score 0.8730 - acc 0.8730 - tp 19729 - fp 1843 - fn 3898 - tn 19729\n",
      "2018-11-29 01:23:51,679 TEST: f-score 0.8730 - acc 0.8730 - tp 19729 - fp 1843 - fn 3898 - tn 19729\n",
      "2018-11-29 01:23:51,680 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:23:51,861 epoch 9 - iter 0/462 - loss 2.17778111\n",
      "2018-11-29 01:24:01,234 epoch 9 - iter 46/462 - loss 2.05656599\n",
      "2018-11-29 01:24:10,558 epoch 9 - iter 92/462 - loss 1.97355410\n",
      "2018-11-29 01:24:19,921 epoch 9 - iter 138/462 - loss 2.01159092\n",
      "2018-11-29 01:24:29,264 epoch 9 - iter 184/462 - loss 1.98265948\n",
      "2018-11-29 01:24:38,586 epoch 9 - iter 230/462 - loss 1.98310486\n",
      "2018-11-29 01:24:49,527 epoch 9 - iter 276/462 - loss 2.00214881\n",
      "2018-11-29 01:25:00,316 epoch 9 - iter 322/462 - loss 2.03252307\n",
      "2018-11-29 01:25:11,201 epoch 9 - iter 368/462 - loss 2.03981428\n",
      "2018-11-29 01:25:22,231 epoch 9 - iter 414/462 - loss 2.02976938\n",
      "2018-11-29 01:25:31,601 epoch 9 - iter 460/462 - loss 2.02889722\n",
      "2018-11-29 01:25:31,683 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:26:48,844 EPOCH 9: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 01:26:48,844 DEV : f-score 0.8805 - acc 0.8805 - tp 20105 - fp 1935 - fn 3522 - tn 20105\n",
      "2018-11-29 01:26:48,845 TEST: f-score 0.8805 - acc 0.8805 - tp 20105 - fp 1935 - fn 3522 - tn 20105\n",
      "2018-11-29 01:26:48,846 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:26:49,105 epoch 10 - iter 0/462 - loss 2.17349195\n",
      "2018-11-29 01:26:59,327 epoch 10 - iter 46/462 - loss 1.97667026\n",
      "2018-11-29 01:27:10,040 epoch 10 - iter 92/462 - loss 1.95363005\n",
      "2018-11-29 01:27:21,199 epoch 10 - iter 138/462 - loss 1.99461453\n",
      "2018-11-29 01:27:31,869 epoch 10 - iter 184/462 - loss 1.97420290\n",
      "2018-11-29 01:27:42,632 epoch 10 - iter 230/462 - loss 1.99141390\n",
      "2018-11-29 01:27:53,535 epoch 10 - iter 276/462 - loss 1.97204984\n",
      "2018-11-29 01:28:04,822 epoch 10 - iter 322/462 - loss 1.98269682\n",
      "2018-11-29 01:28:15,221 epoch 10 - iter 368/462 - loss 1.96934563\n",
      "2018-11-29 01:28:25,685 epoch 10 - iter 414/462 - loss 1.96125309\n",
      "2018-11-29 01:28:36,176 epoch 10 - iter 460/462 - loss 1.96253768\n",
      "2018-11-29 01:28:36,330 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:29:53,629 EPOCH 10: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 01:29:53,629 DEV : f-score 0.8838 - acc 0.8837 - tp 20172 - fp 1853 - fn 3455 - tn 20172\n",
      "2018-11-29 01:29:53,630 TEST: f-score 0.8838 - acc 0.8837 - tp 20172 - fp 1853 - fn 3455 - tn 20172\n",
      "2018-11-29 01:29:53,631 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:29:53,872 epoch 11 - iter 0/462 - loss 1.42304730\n",
      "2018-11-29 01:30:03,532 epoch 11 - iter 46/462 - loss 1.89690647\n",
      "2018-11-29 01:30:12,721 epoch 11 - iter 92/462 - loss 1.89661718\n",
      "2018-11-29 01:30:22,348 epoch 11 - iter 138/462 - loss 1.89792631\n",
      "2018-11-29 01:30:32,462 epoch 11 - iter 184/462 - loss 1.91434735\n",
      "2018-11-29 01:30:43,133 epoch 11 - iter 230/462 - loss 1.88811033\n",
      "2018-11-29 01:30:54,200 epoch 11 - iter 276/462 - loss 1.89961461\n",
      "2018-11-29 01:31:04,998 epoch 11 - iter 322/462 - loss 1.91041118\n",
      "2018-11-29 01:31:15,583 epoch 11 - iter 368/462 - loss 1.91259675\n",
      "2018-11-29 01:31:26,586 epoch 11 - iter 414/462 - loss 1.90796365\n",
      "2018-11-29 01:31:36,267 epoch 11 - iter 460/462 - loss 1.91026448\n",
      "2018-11-29 01:31:36,394 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:32:53,666 EPOCH 11: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 01:32:53,667 DEV : f-score 0.8859 - acc 0.8858 - tp 20196 - fp 1774 - fn 3431 - tn 20196\n",
      "2018-11-29 01:32:53,667 TEST: f-score 0.8859 - acc 0.8858 - tp 20196 - fp 1774 - fn 3431 - tn 20196\n",
      "2018-11-29 01:32:53,668 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:32:53,899 epoch 12 - iter 0/462 - loss 1.91424441\n",
      "2018-11-29 01:33:03,821 epoch 12 - iter 46/462 - loss 1.77975854\n",
      "2018-11-29 01:33:15,229 epoch 12 - iter 92/462 - loss 1.92362545\n",
      "2018-11-29 01:33:25,653 epoch 12 - iter 138/462 - loss 1.88683717\n",
      "2018-11-29 01:33:36,481 epoch 12 - iter 184/462 - loss 1.89293380\n",
      "2018-11-29 01:33:47,445 epoch 12 - iter 230/462 - loss 1.91911740\n",
      "2018-11-29 01:33:57,691 epoch 12 - iter 276/462 - loss 1.90613367\n",
      "2018-11-29 01:34:08,299 epoch 12 - iter 322/462 - loss 1.88759962\n",
      "2018-11-29 01:34:18,680 epoch 12 - iter 368/462 - loss 1.87020783\n",
      "2018-11-29 01:34:29,270 epoch 12 - iter 414/462 - loss 1.88082446\n",
      "2018-11-29 01:34:40,076 epoch 12 - iter 460/462 - loss 1.87933234\n",
      "2018-11-29 01:34:40,152 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:35:57,054 EPOCH 12: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 01:35:57,055 DEV : f-score 0.8833 - acc 0.8833 - tp 20070 - fp 1745 - fn 3557 - tn 20070\n",
      "2018-11-29 01:35:57,056 TEST: f-score 0.8833 - acc 0.8833 - tp 20070 - fp 1745 - fn 3557 - tn 20070\n",
      "2018-11-29 01:35:57,056 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:35:57,295 epoch 13 - iter 0/462 - loss 1.86171699\n",
      "2018-11-29 01:36:06,760 epoch 13 - iter 46/462 - loss 1.77395059\n",
      "2018-11-29 01:36:16,429 epoch 13 - iter 92/462 - loss 1.78204832\n",
      "2018-11-29 01:36:26,245 epoch 13 - iter 138/462 - loss 1.76617694\n",
      "2018-11-29 01:36:35,559 epoch 13 - iter 184/462 - loss 1.78637358\n",
      "2018-11-29 01:36:44,720 epoch 13 - iter 230/462 - loss 1.79061984\n",
      "2018-11-29 01:36:53,983 epoch 13 - iter 276/462 - loss 1.79515662\n",
      "2018-11-29 01:37:03,538 epoch 13 - iter 322/462 - loss 1.83449742\n",
      "2018-11-29 01:37:13,030 epoch 13 - iter 368/462 - loss 1.84540292\n",
      "2018-11-29 01:37:22,733 epoch 13 - iter 414/462 - loss 1.85355704\n",
      "2018-11-29 01:37:32,429 epoch 13 - iter 460/462 - loss 1.85012005\n",
      "2018-11-29 01:37:32,549 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:38:50,140 EPOCH 13: lr 0.1000 - bad epochs 1\n",
      "2018-11-29 01:38:50,141 DEV : f-score 0.8947 - acc 0.8947 - tp 20464 - fp 1652 - fn 3163 - tn 20464\n",
      "2018-11-29 01:38:50,142 TEST: f-score 0.8947 - acc 0.8947 - tp 20464 - fp 1652 - fn 3163 - tn 20464\n",
      "2018-11-29 01:38:50,144 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:38:50,408 epoch 14 - iter 0/462 - loss 1.62386298\n",
      "2018-11-29 01:39:01,218 epoch 14 - iter 46/462 - loss 1.85016957\n",
      "2018-11-29 01:39:11,644 epoch 14 - iter 92/462 - loss 1.82648934\n",
      "2018-11-29 01:39:21,231 epoch 14 - iter 138/462 - loss 1.83447241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-29 01:39:30,639 epoch 14 - iter 184/462 - loss 1.82201212\n",
      "2018-11-29 01:39:39,988 epoch 14 - iter 230/462 - loss 1.82177077\n",
      "2018-11-29 01:39:49,721 epoch 14 - iter 276/462 - loss 1.83609324\n",
      "2018-11-29 01:39:59,449 epoch 14 - iter 322/462 - loss 1.85219731\n",
      "2018-11-29 01:40:08,723 epoch 14 - iter 368/462 - loss 1.83529518\n",
      "2018-11-29 01:40:18,252 epoch 14 - iter 414/462 - loss 1.82956879\n",
      "2018-11-29 01:40:28,860 epoch 14 - iter 460/462 - loss 1.81510421\n",
      "2018-11-29 01:40:28,978 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:41:47,146 EPOCH 14: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 01:41:47,147 DEV : f-score 0.8966 - acc 0.8967 - tp 20721 - fp 1870 - fn 2906 - tn 20721\n",
      "2018-11-29 01:41:47,148 TEST: f-score 0.8966 - acc 0.8967 - tp 20721 - fp 1870 - fn 2906 - tn 20721\n",
      "2018-11-29 01:41:47,148 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:41:47,408 epoch 15 - iter 0/462 - loss 1.81893659\n",
      "2018-11-29 01:41:57,845 epoch 15 - iter 46/462 - loss 1.72060331\n",
      "2018-11-29 01:42:08,558 epoch 15 - iter 92/462 - loss 1.77442145\n",
      "2018-11-29 01:42:19,999 epoch 15 - iter 138/462 - loss 1.78411156\n",
      "2018-11-29 01:42:30,523 epoch 15 - iter 184/462 - loss 1.79746164\n",
      "2018-11-29 01:42:41,720 epoch 15 - iter 230/462 - loss 1.78140556\n",
      "2018-11-29 01:42:52,324 epoch 15 - iter 276/462 - loss 1.78329133\n",
      "2018-11-29 01:43:03,231 epoch 15 - iter 322/462 - loss 1.77809641\n",
      "2018-11-29 01:43:14,394 epoch 15 - iter 368/462 - loss 1.79175190\n",
      "2018-11-29 01:43:25,225 epoch 15 - iter 414/462 - loss 1.79814533\n",
      "2018-11-29 01:43:35,908 epoch 15 - iter 460/462 - loss 1.78314101\n",
      "2018-11-29 01:43:36,066 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:44:55,061 EPOCH 15: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 01:44:55,062 DEV : f-score 0.8982 - acc 0.8982 - tp 20735 - fp 1809 - fn 2892 - tn 20735\n",
      "2018-11-29 01:44:55,062 TEST: f-score 0.8982 - acc 0.8982 - tp 20735 - fp 1809 - fn 2892 - tn 20735\n",
      "2018-11-29 01:44:55,063 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:44:55,299 epoch 16 - iter 0/462 - loss 1.90826237\n",
      "2018-11-29 01:45:06,522 epoch 16 - iter 46/462 - loss 1.68803144\n",
      "2018-11-29 01:45:16,858 epoch 16 - iter 92/462 - loss 1.72303854\n",
      "2018-11-29 01:45:26,111 epoch 16 - iter 138/462 - loss 1.74867632\n",
      "2018-11-29 01:45:35,233 epoch 16 - iter 184/462 - loss 1.74764106\n",
      "2018-11-29 01:45:44,778 epoch 16 - iter 230/462 - loss 1.76361822\n",
      "2018-11-29 01:45:54,327 epoch 16 - iter 276/462 - loss 1.77644718\n",
      "2018-11-29 01:46:03,528 epoch 16 - iter 322/462 - loss 1.79198221\n",
      "2018-11-29 01:46:12,778 epoch 16 - iter 368/462 - loss 1.76515431\n",
      "2018-11-29 01:46:22,255 epoch 16 - iter 414/462 - loss 1.76017188\n",
      "2018-11-29 01:46:31,379 epoch 16 - iter 460/462 - loss 1.73804127\n",
      "2018-11-29 01:46:31,507 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:47:48,567 EPOCH 16: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 01:47:48,568 DEV : f-score 0.9029 - acc 0.9029 - tp 20788 - fp 1631 - fn 2839 - tn 20788\n",
      "2018-11-29 01:47:48,568 TEST: f-score 0.9029 - acc 0.9029 - tp 20788 - fp 1631 - fn 2839 - tn 20788\n",
      "2018-11-29 01:47:48,569 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:47:48,765 epoch 17 - iter 0/462 - loss 2.93252707\n",
      "2018-11-29 01:47:58,893 epoch 17 - iter 46/462 - loss 1.66021819\n",
      "2018-11-29 01:48:09,356 epoch 17 - iter 92/462 - loss 1.76670198\n",
      "2018-11-29 01:48:20,496 epoch 17 - iter 138/462 - loss 1.78323384\n",
      "2018-11-29 01:48:31,295 epoch 17 - iter 184/462 - loss 1.76056252\n",
      "2018-11-29 01:48:42,155 epoch 17 - iter 230/462 - loss 1.74328740\n",
      "2018-11-29 01:48:52,726 epoch 17 - iter 276/462 - loss 1.72467547\n",
      "2018-11-29 01:49:03,475 epoch 17 - iter 322/462 - loss 1.71267588\n",
      "2018-11-29 01:49:14,188 epoch 17 - iter 368/462 - loss 1.72150143\n",
      "2018-11-29 01:49:24,535 epoch 17 - iter 414/462 - loss 1.72408926\n",
      "2018-11-29 01:49:35,307 epoch 17 - iter 460/462 - loss 1.73602472\n",
      "2018-11-29 01:49:35,460 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:50:53,218 EPOCH 17: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 01:50:53,218 DEV : f-score 0.8959 - acc 0.8959 - tp 20603 - fp 1762 - fn 3024 - tn 20603\n",
      "2018-11-29 01:50:53,219 TEST: f-score 0.8959 - acc 0.8959 - tp 20603 - fp 1762 - fn 3024 - tn 20603\n",
      "2018-11-29 01:50:53,220 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:50:53,465 epoch 18 - iter 0/462 - loss 1.43116379\n",
      "2018-11-29 01:51:04,177 epoch 18 - iter 46/462 - loss 1.66236425\n",
      "2018-11-29 01:51:14,871 epoch 18 - iter 92/462 - loss 1.71823544\n",
      "2018-11-29 01:51:25,608 epoch 18 - iter 138/462 - loss 1.67548950\n",
      "2018-11-29 01:51:36,893 epoch 18 - iter 184/462 - loss 1.66486886\n",
      "2018-11-29 01:51:47,314 epoch 18 - iter 230/462 - loss 1.67506871\n",
      "2018-11-29 01:51:57,322 epoch 18 - iter 276/462 - loss 1.69454781\n",
      "2018-11-29 01:52:06,854 epoch 18 - iter 322/462 - loss 1.70716129\n",
      "2018-11-29 01:52:16,153 epoch 18 - iter 368/462 - loss 1.70563335\n",
      "2018-11-29 01:52:25,657 epoch 18 - iter 414/462 - loss 1.70371243\n",
      "2018-11-29 01:52:35,059 epoch 18 - iter 460/462 - loss 1.71886130\n",
      "2018-11-29 01:52:35,178 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:53:52,797 EPOCH 18: lr 0.1000 - bad epochs 1\n",
      "2018-11-29 01:53:52,798 DEV : f-score 0.9054 - acc 0.9054 - tp 20984 - fp 1742 - fn 2643 - tn 20984\n",
      "2018-11-29 01:53:52,799 TEST: f-score 0.9054 - acc 0.9054 - tp 20984 - fp 1742 - fn 2643 - tn 20984\n",
      "2018-11-29 01:53:52,800 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:53:53,049 epoch 19 - iter 0/462 - loss 0.93601966\n",
      "2018-11-29 01:54:02,508 epoch 19 - iter 46/462 - loss 1.78087338\n",
      "2018-11-29 01:54:11,916 epoch 19 - iter 92/462 - loss 1.81535385\n",
      "2018-11-29 01:54:21,348 epoch 19 - iter 138/462 - loss 1.75733113\n",
      "2018-11-29 01:54:31,094 epoch 19 - iter 184/462 - loss 1.72024683\n",
      "2018-11-29 01:54:40,549 epoch 19 - iter 230/462 - loss 1.71216594\n",
      "2018-11-29 01:54:50,293 epoch 19 - iter 276/462 - loss 1.71390876\n",
      "2018-11-29 01:54:59,167 epoch 19 - iter 322/462 - loss 1.68961486\n",
      "2018-11-29 01:55:08,490 epoch 19 - iter 368/462 - loss 1.68473185\n",
      "2018-11-29 01:55:17,987 epoch 19 - iter 414/462 - loss 1.70546856\n",
      "2018-11-29 01:55:27,270 epoch 19 - iter 460/462 - loss 1.69621812\n",
      "2018-11-29 01:55:27,365 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:56:44,635 EPOCH 19: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 01:56:44,636 DEV : f-score 0.9068 - acc 0.9068 - tp 20976 - fp 1660 - fn 2651 - tn 20976\n",
      "2018-11-29 01:56:44,637 TEST: f-score 0.9068 - acc 0.9068 - tp 20976 - fp 1660 - fn 2651 - tn 20976\n",
      "2018-11-29 01:56:44,638 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:56:44,852 epoch 20 - iter 0/462 - loss 2.60180211\n",
      "2018-11-29 01:56:56,067 epoch 20 - iter 46/462 - loss 1.61341200\n",
      "2018-11-29 01:57:07,400 epoch 20 - iter 92/462 - loss 1.69802857\n",
      "2018-11-29 01:57:17,912 epoch 20 - iter 138/462 - loss 1.65689467\n",
      "2018-11-29 01:57:28,700 epoch 20 - iter 184/462 - loss 1.66389033\n",
      "2018-11-29 01:57:39,427 epoch 20 - iter 230/462 - loss 1.66977892\n",
      "2018-11-29 01:57:49,672 epoch 20 - iter 276/462 - loss 1.66245936\n",
      "2018-11-29 01:58:00,975 epoch 20 - iter 322/462 - loss 1.65797448\n",
      "2018-11-29 01:58:12,007 epoch 20 - iter 368/462 - loss 1.66379611\n",
      "2018-11-29 01:58:23,041 epoch 20 - iter 414/462 - loss 1.66822305\n",
      "2018-11-29 01:58:34,323 epoch 20 - iter 460/462 - loss 1.68331926\n",
      "2018-11-29 01:58:34,472 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:59:51,903 EPOCH 20: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 01:59:51,904 DEV : f-score 0.9088 - acc 0.9088 - tp 20930 - fp 1506 - fn 2697 - tn 20930\n",
      "2018-11-29 01:59:51,904 TEST: f-score 0.9088 - acc 0.9088 - tp 20930 - fp 1506 - fn 2697 - tn 20930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-29 01:59:51,905 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 01:59:52,112 epoch 21 - iter 0/462 - loss 0.93344438\n",
      "2018-11-29 02:00:02,936 epoch 21 - iter 46/462 - loss 1.64582259\n",
      "2018-11-29 02:00:13,239 epoch 21 - iter 92/462 - loss 1.70821893\n",
      "2018-11-29 02:00:23,949 epoch 21 - iter 138/462 - loss 1.70152836\n",
      "2018-11-29 02:00:33,635 epoch 21 - iter 184/462 - loss 1.68350503\n",
      "2018-11-29 02:00:43,065 epoch 21 - iter 230/462 - loss 1.71820870\n",
      "2018-11-29 02:00:52,619 epoch 21 - iter 276/462 - loss 1.72387379\n",
      "2018-11-29 02:01:02,036 epoch 21 - iter 322/462 - loss 1.69021509\n",
      "2018-11-29 02:01:11,485 epoch 21 - iter 368/462 - loss 1.68793401\n",
      "2018-11-29 02:01:21,011 epoch 21 - iter 414/462 - loss 1.68958470\n",
      "2018-11-29 02:01:29,725 epoch 21 - iter 460/462 - loss 1.67533234\n",
      "2018-11-29 02:01:29,838 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:02:47,600 EPOCH 21: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 02:02:47,601 DEV : f-score 0.9098 - acc 0.9098 - tp 21112 - fp 1670 - fn 2515 - tn 21112\n",
      "2018-11-29 02:02:47,601 TEST: f-score 0.9098 - acc 0.9098 - tp 21112 - fp 1670 - fn 2515 - tn 21112\n",
      "2018-11-29 02:02:47,602 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:02:47,843 epoch 22 - iter 0/462 - loss 1.16935325\n",
      "2018-11-29 02:02:56,962 epoch 22 - iter 46/462 - loss 1.57276676\n",
      "2018-11-29 02:03:06,236 epoch 22 - iter 92/462 - loss 1.61890701\n",
      "2018-11-29 02:03:15,485 epoch 22 - iter 138/462 - loss 1.62331702\n",
      "2018-11-29 02:03:25,152 epoch 22 - iter 184/462 - loss 1.68764772\n",
      "2018-11-29 02:03:34,360 epoch 22 - iter 230/462 - loss 1.67285709\n",
      "2018-11-29 02:03:43,674 epoch 22 - iter 276/462 - loss 1.67090652\n",
      "2018-11-29 02:03:53,237 epoch 22 - iter 322/462 - loss 1.65322222\n",
      "2018-11-29 02:04:03,044 epoch 22 - iter 368/462 - loss 1.64685729\n",
      "2018-11-29 02:04:12,511 epoch 22 - iter 414/462 - loss 1.67171336\n",
      "2018-11-29 02:04:22,080 epoch 22 - iter 460/462 - loss 1.65592581\n",
      "2018-11-29 02:04:22,178 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:05:39,631 EPOCH 22: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 02:05:39,632 DEV : f-score 0.9069 - acc 0.9069 - tp 20920 - fp 1587 - fn 2707 - tn 20920\n",
      "2018-11-29 02:05:39,632 TEST: f-score 0.9069 - acc 0.9069 - tp 20920 - fp 1587 - fn 2707 - tn 20920\n",
      "2018-11-29 02:05:39,635 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:05:39,832 epoch 23 - iter 0/462 - loss 0.92515838\n",
      "2018-11-29 02:05:50,510 epoch 23 - iter 46/462 - loss 1.66968466\n",
      "2018-11-29 02:06:01,344 epoch 23 - iter 92/462 - loss 1.60604430\n",
      "2018-11-29 02:06:12,222 epoch 23 - iter 138/462 - loss 1.61340591\n",
      "2018-11-29 02:06:23,366 epoch 23 - iter 184/462 - loss 1.59336104\n",
      "2018-11-29 02:06:34,692 epoch 23 - iter 230/462 - loss 1.61352962\n",
      "2018-11-29 02:06:45,693 epoch 23 - iter 276/462 - loss 1.62213758\n",
      "2018-11-29 02:06:56,358 epoch 23 - iter 322/462 - loss 1.61865365\n",
      "2018-11-29 02:07:06,821 epoch 23 - iter 368/462 - loss 1.61193387\n",
      "2018-11-29 02:07:17,624 epoch 23 - iter 414/462 - loss 1.61308481\n",
      "2018-11-29 02:07:28,444 epoch 23 - iter 460/462 - loss 1.62350861\n",
      "2018-11-29 02:07:28,605 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:08:46,321 EPOCH 23: lr 0.1000 - bad epochs 1\n",
      "2018-11-29 02:08:46,321 DEV : f-score 0.9086 - acc 0.9086 - tp 20782 - fp 1338 - fn 2845 - tn 20782\n",
      "2018-11-29 02:08:46,322 TEST: f-score 0.9086 - acc 0.9086 - tp 20782 - fp 1338 - fn 2845 - tn 20782\n",
      "2018-11-29 02:08:46,323 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:08:46,577 epoch 24 - iter 0/462 - loss 1.61462891\n",
      "2018-11-29 02:08:57,215 epoch 24 - iter 46/462 - loss 1.51003159\n",
      "2018-11-29 02:09:07,346 epoch 24 - iter 92/462 - loss 1.50146126\n",
      "2018-11-29 02:09:18,223 epoch 24 - iter 138/462 - loss 1.52205510\n",
      "2018-11-29 02:09:28,792 epoch 24 - iter 184/462 - loss 1.53697980\n",
      "2018-11-29 02:09:39,281 epoch 24 - iter 230/462 - loss 1.55267514\n",
      "2018-11-29 02:09:50,049 epoch 24 - iter 276/462 - loss 1.57430777\n",
      "2018-11-29 02:10:01,053 epoch 24 - iter 322/462 - loss 1.62235624\n",
      "2018-11-29 02:10:11,799 epoch 24 - iter 368/462 - loss 1.61489086\n",
      "2018-11-29 02:10:22,676 epoch 24 - iter 414/462 - loss 1.62531754\n",
      "2018-11-29 02:10:33,284 epoch 24 - iter 460/462 - loss 1.62591144\n",
      "2018-11-29 02:10:33,442 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:11:51,497 EPOCH 24: lr 0.1000 - bad epochs 2\n",
      "2018-11-29 02:11:51,498 DEV : f-score 0.9152 - acc 0.9152 - tp 21102 - fp 1383 - fn 2525 - tn 21102\n",
      "2018-11-29 02:11:51,499 TEST: f-score 0.9152 - acc 0.9152 - tp 21102 - fp 1383 - fn 2525 - tn 21102\n",
      "2018-11-29 02:11:51,502 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:11:51,720 epoch 25 - iter 0/462 - loss 0.97361124\n",
      "2018-11-29 02:12:01,099 epoch 25 - iter 46/462 - loss 1.79319868\n",
      "2018-11-29 02:12:11,112 epoch 25 - iter 92/462 - loss 1.72904446\n",
      "2018-11-29 02:12:21,136 epoch 25 - iter 138/462 - loss 1.68091295\n",
      "2018-11-29 02:12:31,813 epoch 25 - iter 184/462 - loss 1.67586210\n",
      "2018-11-29 02:12:43,040 epoch 25 - iter 230/462 - loss 1.67392008\n",
      "2018-11-29 02:12:53,338 epoch 25 - iter 276/462 - loss 1.63723083\n",
      "2018-11-29 02:13:03,565 epoch 25 - iter 322/462 - loss 1.64990109\n",
      "2018-11-29 02:13:14,385 epoch 25 - iter 368/462 - loss 1.64184301\n",
      "2018-11-29 02:13:25,036 epoch 25 - iter 414/462 - loss 1.63118785\n",
      "2018-11-29 02:13:34,487 epoch 25 - iter 460/462 - loss 1.61613101\n",
      "2018-11-29 02:13:34,590 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:14:52,071 EPOCH 25: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 02:14:52,072 DEV : f-score 0.9173 - acc 0.9173 - tp 21257 - fp 1461 - fn 2370 - tn 21257\n",
      "2018-11-29 02:14:52,073 TEST: f-score 0.9173 - acc 0.9173 - tp 21257 - fp 1461 - fn 2370 - tn 21257\n",
      "2018-11-29 02:14:52,074 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:14:52,323 epoch 26 - iter 0/462 - loss 1.25589752\n",
      "2018-11-29 02:15:03,541 epoch 26 - iter 46/462 - loss 1.80572435\n",
      "2018-11-29 02:15:13,648 epoch 26 - iter 92/462 - loss 1.69262761\n",
      "2018-11-29 02:15:22,818 epoch 26 - iter 138/462 - loss 1.60613801\n",
      "2018-11-29 02:15:32,208 epoch 26 - iter 184/462 - loss 1.59551751\n",
      "2018-11-29 02:15:41,756 epoch 26 - iter 230/462 - loss 1.58974564\n",
      "2018-11-29 02:15:50,967 epoch 26 - iter 276/462 - loss 1.58122250\n",
      "2018-11-29 02:16:00,046 epoch 26 - iter 322/462 - loss 1.55572736\n",
      "2018-11-29 02:16:09,446 epoch 26 - iter 368/462 - loss 1.58562481\n",
      "2018-11-29 02:16:18,904 epoch 26 - iter 414/462 - loss 1.58586241\n",
      "2018-11-29 02:16:28,340 epoch 26 - iter 460/462 - loss 1.58699157\n",
      "2018-11-29 02:16:28,447 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:17:45,638 EPOCH 26: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 02:17:45,639 DEV : f-score 0.9172 - acc 0.9172 - tp 21294 - fp 1514 - fn 2333 - tn 21294\n",
      "2018-11-29 02:17:45,639 TEST: f-score 0.9172 - acc 0.9172 - tp 21294 - fp 1514 - fn 2333 - tn 21294\n",
      "2018-11-29 02:17:45,642 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:17:45,866 epoch 27 - iter 0/462 - loss 1.85183120\n",
      "2018-11-29 02:17:56,571 epoch 27 - iter 46/462 - loss 1.59315837\n",
      "2018-11-29 02:18:07,996 epoch 27 - iter 92/462 - loss 1.61358037\n",
      "2018-11-29 02:18:19,219 epoch 27 - iter 138/462 - loss 1.61814051\n",
      "2018-11-29 02:18:29,740 epoch 27 - iter 184/462 - loss 1.61416484\n",
      "2018-11-29 02:18:40,321 epoch 27 - iter 230/462 - loss 1.57933099\n",
      "2018-11-29 02:18:51,426 epoch 27 - iter 276/462 - loss 1.58819318\n",
      "2018-11-29 02:19:00,975 epoch 27 - iter 322/462 - loss 1.58105738\n",
      "2018-11-29 02:19:10,104 epoch 27 - iter 368/462 - loss 1.58724092\n",
      "2018-11-29 02:19:19,232 epoch 27 - iter 414/462 - loss 1.57806221\n",
      "2018-11-29 02:19:28,771 epoch 27 - iter 460/462 - loss 1.59881899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-29 02:19:28,855 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:20:46,226 EPOCH 27: lr 0.1000 - bad epochs 1\n",
      "2018-11-29 02:20:46,227 DEV : f-score 0.9180 - acc 0.9180 - tp 21273 - fp 1445 - fn 2354 - tn 21273\n",
      "2018-11-29 02:20:46,227 TEST: f-score 0.9180 - acc 0.9180 - tp 21273 - fp 1445 - fn 2354 - tn 21273\n",
      "2018-11-29 02:20:46,228 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:20:46,428 epoch 28 - iter 0/462 - loss 1.72887146\n",
      "2018-11-29 02:20:55,741 epoch 28 - iter 46/462 - loss 1.50692750\n",
      "2018-11-29 02:21:05,020 epoch 28 - iter 92/462 - loss 1.47013050\n",
      "2018-11-29 02:21:14,531 epoch 28 - iter 138/462 - loss 1.51538355\n",
      "2018-11-29 02:21:23,776 epoch 28 - iter 184/462 - loss 1.54053133\n",
      "2018-11-29 02:21:33,482 epoch 28 - iter 230/462 - loss 1.55179512\n",
      "2018-11-29 02:21:43,126 epoch 28 - iter 276/462 - loss 1.56868326\n",
      "2018-11-29 02:21:52,682 epoch 28 - iter 322/462 - loss 1.57295958\n",
      "2018-11-29 02:22:02,034 epoch 28 - iter 368/462 - loss 1.56550290\n",
      "2018-11-29 02:22:11,252 epoch 28 - iter 414/462 - loss 1.56279918\n",
      "2018-11-29 02:22:20,488 epoch 28 - iter 460/462 - loss 1.57197442\n",
      "2018-11-29 02:22:20,600 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:23:38,133 EPOCH 28: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 02:23:38,134 DEV : f-score 0.9190 - acc 0.9190 - tp 21244 - fp 1362 - fn 2383 - tn 21244\n",
      "2018-11-29 02:23:38,134 TEST: f-score 0.9190 - acc 0.9190 - tp 21244 - fp 1362 - fn 2383 - tn 21244\n",
      "2018-11-29 02:23:38,135 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:23:38,391 epoch 29 - iter 0/462 - loss 1.24642599\n",
      "2018-11-29 02:23:48,402 epoch 29 - iter 46/462 - loss 1.46936935\n",
      "2018-11-29 02:23:58,970 epoch 29 - iter 92/462 - loss 1.43577226\n",
      "2018-11-29 02:24:10,040 epoch 29 - iter 138/462 - loss 1.48574546\n",
      "2018-11-29 02:24:21,067 epoch 29 - iter 184/462 - loss 1.51924861\n",
      "2018-11-29 02:24:31,815 epoch 29 - iter 230/462 - loss 1.53140558\n",
      "2018-11-29 02:24:42,676 epoch 29 - iter 276/462 - loss 1.52620407\n",
      "2018-11-29 02:24:53,823 epoch 29 - iter 322/462 - loss 1.52972312\n",
      "2018-11-29 02:25:04,885 epoch 29 - iter 368/462 - loss 1.53185104\n",
      "2018-11-29 02:25:15,519 epoch 29 - iter 414/462 - loss 1.54031598\n",
      "2018-11-29 02:25:26,161 epoch 29 - iter 460/462 - loss 1.53157056\n",
      "2018-11-29 02:25:26,309 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:26:44,281 EPOCH 29: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 02:26:44,282 DEV : f-score 0.9202 - acc 0.9202 - tp 21422 - fp 1511 - fn 2205 - tn 21422\n",
      "2018-11-29 02:26:44,283 TEST: f-score 0.9202 - acc 0.9202 - tp 21422 - fp 1511 - fn 2205 - tn 21422\n",
      "2018-11-29 02:26:44,285 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:26:44,505 epoch 30 - iter 0/462 - loss 1.57007456\n",
      "2018-11-29 02:26:55,177 epoch 30 - iter 46/462 - loss 1.47482284\n",
      "2018-11-29 02:27:06,155 epoch 30 - iter 92/462 - loss 1.55600206\n",
      "2018-11-29 02:27:16,607 epoch 30 - iter 138/462 - loss 1.55164956\n",
      "2018-11-29 02:27:27,178 epoch 30 - iter 184/462 - loss 1.54715498\n",
      "2018-11-29 02:27:38,065 epoch 30 - iter 230/462 - loss 1.55702538\n",
      "2018-11-29 02:27:48,672 epoch 30 - iter 276/462 - loss 1.57152251\n",
      "2018-11-29 02:27:59,222 epoch 30 - iter 322/462 - loss 1.56081122\n",
      "2018-11-29 02:28:10,329 epoch 30 - iter 368/462 - loss 1.56178159\n",
      "2018-11-29 02:28:21,416 epoch 30 - iter 414/462 - loss 1.56179966\n",
      "2018-11-29 02:28:32,914 epoch 30 - iter 460/462 - loss 1.56358704\n",
      "2018-11-29 02:28:33,059 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:29:50,876 EPOCH 30: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 02:29:50,877 DEV : f-score 0.9223 - acc 0.9222 - tp 21382 - fp 1361 - fn 2245 - tn 21382\n",
      "2018-11-29 02:29:50,878 TEST: f-score 0.9223 - acc 0.9222 - tp 21382 - fp 1361 - fn 2245 - tn 21382\n",
      "2018-11-29 02:29:50,878 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:29:51,155 epoch 31 - iter 0/462 - loss 1.98389113\n",
      "2018-11-29 02:30:01,512 epoch 31 - iter 46/462 - loss 1.46437683\n",
      "2018-11-29 02:30:12,062 epoch 31 - iter 92/462 - loss 1.48737459\n",
      "2018-11-29 02:30:22,721 epoch 31 - iter 138/462 - loss 1.54003233\n",
      "2018-11-29 02:30:32,105 epoch 31 - iter 184/462 - loss 1.54827439\n",
      "2018-11-29 02:30:42,082 epoch 31 - iter 230/462 - loss 1.55740466\n",
      "2018-11-29 02:30:52,732 epoch 31 - iter 276/462 - loss 1.54921250\n",
      "2018-11-29 02:31:03,831 epoch 31 - iter 322/462 - loss 1.54907158\n",
      "2018-11-29 02:31:14,694 epoch 31 - iter 368/462 - loss 1.54968371\n",
      "2018-11-29 02:31:24,997 epoch 31 - iter 414/462 - loss 1.53761546\n",
      "2018-11-29 02:31:34,385 epoch 31 - iter 460/462 - loss 1.53599478\n",
      "2018-11-29 02:31:34,518 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:32:52,214 EPOCH 31: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 02:32:52,215 DEV : f-score 0.9233 - acc 0.9234 - tp 21572 - fp 1526 - fn 2055 - tn 21572\n",
      "2018-11-29 02:32:52,216 TEST: f-score 0.9233 - acc 0.9234 - tp 21572 - fp 1526 - fn 2055 - tn 21572\n",
      "2018-11-29 02:32:52,217 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:32:52,419 epoch 32 - iter 0/462 - loss 1.72291315\n",
      "2018-11-29 02:33:02,931 epoch 32 - iter 46/462 - loss 1.52089165\n",
      "2018-11-29 02:33:13,826 epoch 32 - iter 92/462 - loss 1.56576436\n",
      "2018-11-29 02:33:24,166 epoch 32 - iter 138/462 - loss 1.55157614\n",
      "2018-11-29 02:33:34,150 epoch 32 - iter 184/462 - loss 1.58239730\n",
      "2018-11-29 02:33:44,600 epoch 32 - iter 230/462 - loss 1.55826711\n",
      "2018-11-29 02:33:55,178 epoch 32 - iter 276/462 - loss 1.55483454\n",
      "2018-11-29 02:34:06,399 epoch 32 - iter 322/462 - loss 1.56668120\n",
      "2018-11-29 02:34:16,620 epoch 32 - iter 368/462 - loss 1.54547733\n",
      "2018-11-29 02:34:26,184 epoch 32 - iter 414/462 - loss 1.55520272\n",
      "2018-11-29 02:34:35,597 epoch 32 - iter 460/462 - loss 1.55652610\n",
      "2018-11-29 02:34:35,703 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:35:53,130 EPOCH 32: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 02:35:53,131 DEV : f-score 0.9232 - acc 0.9232 - tp 21403 - fp 1337 - fn 2224 - tn 21403\n",
      "2018-11-29 02:35:53,132 TEST: f-score 0.9232 - acc 0.9232 - tp 21403 - fp 1337 - fn 2224 - tn 21403\n",
      "2018-11-29 02:35:53,133 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:35:53,372 epoch 33 - iter 0/462 - loss 1.98729682\n",
      "2018-11-29 02:36:04,354 epoch 33 - iter 46/462 - loss 1.49912505\n",
      "2018-11-29 02:36:15,161 epoch 33 - iter 92/462 - loss 1.56744541\n",
      "2018-11-29 02:36:25,815 epoch 33 - iter 138/462 - loss 1.53190204\n",
      "2018-11-29 02:36:36,324 epoch 33 - iter 184/462 - loss 1.55769367\n",
      "2018-11-29 02:36:47,071 epoch 33 - iter 230/462 - loss 1.57343757\n",
      "2018-11-29 02:36:57,939 epoch 33 - iter 276/462 - loss 1.55559312\n",
      "2018-11-29 02:37:08,995 epoch 33 - iter 322/462 - loss 1.55368309\n",
      "2018-11-29 02:37:20,033 epoch 33 - iter 368/462 - loss 1.55556775\n",
      "2018-11-29 02:37:30,899 epoch 33 - iter 414/462 - loss 1.56434182\n",
      "2018-11-29 02:37:41,702 epoch 33 - iter 460/462 - loss 1.56412403\n",
      "2018-11-29 02:37:41,873 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:38:59,439 EPOCH 33: lr 0.1000 - bad epochs 1\n",
      "2018-11-29 02:38:59,440 DEV : f-score 0.9249 - acc 0.9249 - tp 21444 - fp 1301 - fn 2183 - tn 21444\n",
      "2018-11-29 02:38:59,440 TEST: f-score 0.9249 - acc 0.9249 - tp 21444 - fp 1301 - fn 2183 - tn 21444\n",
      "2018-11-29 02:38:59,447 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:38:59,723 epoch 34 - iter 0/462 - loss 0.96701807\n",
      "2018-11-29 02:39:10,682 epoch 34 - iter 46/462 - loss 1.51019647\n",
      "2018-11-29 02:39:21,243 epoch 34 - iter 92/462 - loss 1.52687348\n",
      "2018-11-29 02:39:32,165 epoch 34 - iter 138/462 - loss 1.50597566\n",
      "2018-11-29 02:39:43,120 epoch 34 - iter 184/462 - loss 1.53821378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-29 02:39:53,039 epoch 34 - iter 230/462 - loss 1.54928789\n",
      "2018-11-29 02:40:03,752 epoch 34 - iter 276/462 - loss 1.54829609\n",
      "2018-11-29 02:40:14,055 epoch 34 - iter 322/462 - loss 1.51922706\n",
      "2018-11-29 02:40:23,773 epoch 34 - iter 368/462 - loss 1.52306902\n",
      "2018-11-29 02:40:33,006 epoch 34 - iter 414/462 - loss 1.52264981\n",
      "2018-11-29 02:40:42,598 epoch 34 - iter 460/462 - loss 1.52312919\n",
      "2018-11-29 02:40:42,698 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:42:00,373 EPOCH 34: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 02:42:00,374 DEV : f-score 0.9247 - acc 0.9247 - tp 21394 - fp 1253 - fn 2233 - tn 21394\n",
      "2018-11-29 02:42:00,375 TEST: f-score 0.9247 - acc 0.9247 - tp 21394 - fp 1253 - fn 2233 - tn 21394\n",
      "2018-11-29 02:42:00,376 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:42:00,579 epoch 35 - iter 0/462 - loss 0.78271437\n",
      "2018-11-29 02:42:11,006 epoch 35 - iter 46/462 - loss 1.48920088\n",
      "2018-11-29 02:42:21,636 epoch 35 - iter 92/462 - loss 1.52959108\n",
      "2018-11-29 02:42:32,160 epoch 35 - iter 138/462 - loss 1.60261949\n",
      "2018-11-29 02:42:41,530 epoch 35 - iter 184/462 - loss 1.59502497\n",
      "2018-11-29 02:42:50,934 epoch 35 - iter 230/462 - loss 1.58927414\n",
      "2018-11-29 02:43:00,557 epoch 35 - iter 276/462 - loss 1.59274408\n",
      "2018-11-29 02:43:10,117 epoch 35 - iter 322/462 - loss 1.57080666\n",
      "2018-11-29 02:43:19,688 epoch 35 - iter 368/462 - loss 1.56069286\n",
      "2018-11-29 02:43:28,973 epoch 35 - iter 414/462 - loss 1.54223164\n",
      "2018-11-29 02:43:38,646 epoch 35 - iter 460/462 - loss 1.53900493\n",
      "2018-11-29 02:43:38,760 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:44:56,224 EPOCH 35: lr 0.1000 - bad epochs 1\n",
      "2018-11-29 02:44:56,225 DEV : f-score 0.9235 - acc 0.9235 - tp 21485 - fp 1417 - fn 2142 - tn 21485\n",
      "2018-11-29 02:44:56,226 TEST: f-score 0.9235 - acc 0.9235 - tp 21485 - fp 1417 - fn 2142 - tn 21485\n",
      "2018-11-29 02:44:56,227 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:44:56,474 epoch 36 - iter 0/462 - loss 2.07195568\n",
      "2018-11-29 02:45:07,001 epoch 36 - iter 46/462 - loss 1.50941359\n",
      "2018-11-29 02:45:17,800 epoch 36 - iter 92/462 - loss 1.49142127\n",
      "2018-11-29 02:45:28,730 epoch 36 - iter 138/462 - loss 1.50041633\n",
      "2018-11-29 02:45:39,757 epoch 36 - iter 184/462 - loss 1.49082298\n",
      "2018-11-29 02:45:50,630 epoch 36 - iter 230/462 - loss 1.47714457\n",
      "2018-11-29 02:46:02,058 epoch 36 - iter 276/462 - loss 1.47319581\n",
      "2018-11-29 02:46:12,935 epoch 36 - iter 322/462 - loss 1.48616364\n",
      "2018-11-29 02:46:23,684 epoch 36 - iter 368/462 - loss 1.49789112\n",
      "2018-11-29 02:46:34,308 epoch 36 - iter 414/462 - loss 1.50315698\n",
      "2018-11-29 02:46:43,383 epoch 36 - iter 460/462 - loss 1.50791856\n",
      "2018-11-29 02:46:43,483 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:48:01,074 EPOCH 36: lr 0.1000 - bad epochs 2\n",
      "2018-11-29 02:48:01,075 DEV : f-score 0.9257 - acc 0.9257 - tp 21493 - fp 1316 - fn 2134 - tn 21493\n",
      "2018-11-29 02:48:01,076 TEST: f-score 0.9257 - acc 0.9257 - tp 21493 - fp 1316 - fn 2134 - tn 21493\n",
      "2018-11-29 02:48:01,077 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:48:01,279 epoch 37 - iter 0/462 - loss 1.10766566\n",
      "2018-11-29 02:48:11,174 epoch 37 - iter 46/462 - loss 1.42498851\n",
      "2018-11-29 02:48:20,958 epoch 37 - iter 92/462 - loss 1.40775500\n",
      "2018-11-29 02:48:30,289 epoch 37 - iter 138/462 - loss 1.42632833\n",
      "2018-11-29 02:48:39,703 epoch 37 - iter 184/462 - loss 1.42155658\n",
      "2018-11-29 02:48:49,086 epoch 37 - iter 230/462 - loss 1.42092873\n",
      "2018-11-29 02:48:58,373 epoch 37 - iter 276/462 - loss 1.41946477\n",
      "2018-11-29 02:49:07,809 epoch 37 - iter 322/462 - loss 1.44919034\n",
      "2018-11-29 02:49:17,281 epoch 37 - iter 368/462 - loss 1.46593890\n",
      "2018-11-29 02:49:26,965 epoch 37 - iter 414/462 - loss 1.47594860\n",
      "2018-11-29 02:49:36,303 epoch 37 - iter 460/462 - loss 1.47355055\n",
      "2018-11-29 02:49:36,424 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:50:54,020 EPOCH 37: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 02:50:54,021 DEV : f-score 0.9277 - acc 0.9277 - tp 21493 - fp 1216 - fn 2134 - tn 21493\n",
      "2018-11-29 02:50:54,021 TEST: f-score 0.9277 - acc 0.9277 - tp 21493 - fp 1216 - fn 2134 - tn 21493\n",
      "2018-11-29 02:50:54,023 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:50:54,280 epoch 38 - iter 0/462 - loss 1.67613196\n",
      "2018-11-29 02:51:03,500 epoch 38 - iter 46/462 - loss 1.61610654\n",
      "2018-11-29 02:51:12,950 epoch 38 - iter 92/462 - loss 1.61013222\n",
      "2018-11-29 02:51:22,674 epoch 38 - iter 138/462 - loss 1.57329267\n",
      "2018-11-29 02:51:32,275 epoch 38 - iter 184/462 - loss 1.53554551\n",
      "2018-11-29 02:51:42,422 epoch 38 - iter 230/462 - loss 1.53890889\n",
      "2018-11-29 02:51:52,322 epoch 38 - iter 276/462 - loss 1.54360892\n",
      "2018-11-29 02:52:01,528 epoch 38 - iter 322/462 - loss 1.53783994\n",
      "2018-11-29 02:52:10,999 epoch 38 - iter 368/462 - loss 1.53479941\n",
      "2018-11-29 02:52:20,468 epoch 38 - iter 414/462 - loss 1.53423486\n",
      "2018-11-29 02:52:29,709 epoch 38 - iter 460/462 - loss 1.52445464\n",
      "2018-11-29 02:52:29,807 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:53:47,350 EPOCH 38: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 02:53:47,351 DEV : f-score 0.9271 - acc 0.9271 - tp 21699 - fp 1483 - fn 1928 - tn 21699\n",
      "2018-11-29 02:53:47,352 TEST: f-score 0.9271 - acc 0.9271 - tp 21699 - fp 1483 - fn 1928 - tn 21699\n",
      "2018-11-29 02:53:47,353 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:53:47,655 epoch 39 - iter 0/462 - loss 2.06689191\n",
      "2018-11-29 02:53:56,929 epoch 39 - iter 46/462 - loss 1.45786216\n",
      "2018-11-29 02:54:06,526 epoch 39 - iter 92/462 - loss 1.44506153\n",
      "2018-11-29 02:54:15,986 epoch 39 - iter 138/462 - loss 1.50055727\n",
      "2018-11-29 02:54:25,617 epoch 39 - iter 184/462 - loss 1.52191590\n",
      "2018-11-29 02:54:34,887 epoch 39 - iter 230/462 - loss 1.51062116\n",
      "2018-11-29 02:54:43,884 epoch 39 - iter 276/462 - loss 1.50890114\n",
      "2018-11-29 02:54:53,387 epoch 39 - iter 322/462 - loss 1.50874236\n",
      "2018-11-29 02:55:03,061 epoch 39 - iter 368/462 - loss 1.52252279\n",
      "2018-11-29 02:55:12,046 epoch 39 - iter 414/462 - loss 1.50815675\n",
      "2018-11-29 02:55:21,930 epoch 39 - iter 460/462 - loss 1.50385562\n",
      "2018-11-29 02:55:22,047 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:56:39,856 EPOCH 39: lr 0.1000 - bad epochs 1\n",
      "2018-11-29 02:56:39,857 DEV : f-score 0.9292 - acc 0.9293 - tp 21582 - fp 1241 - fn 2045 - tn 21582\n",
      "2018-11-29 02:56:39,857 TEST: f-score 0.9292 - acc 0.9293 - tp 21582 - fp 1241 - fn 2045 - tn 21582\n",
      "2018-11-29 02:56:39,859 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:56:40,107 epoch 40 - iter 0/462 - loss 1.52368999\n",
      "2018-11-29 02:56:49,478 epoch 40 - iter 46/462 - loss 1.44081563\n",
      "2018-11-29 02:56:58,692 epoch 40 - iter 92/462 - loss 1.48165118\n",
      "2018-11-29 02:57:08,504 epoch 40 - iter 138/462 - loss 1.47420668\n",
      "2018-11-29 02:57:18,065 epoch 40 - iter 184/462 - loss 1.47613664\n",
      "2018-11-29 02:57:27,233 epoch 40 - iter 230/462 - loss 1.46741094\n",
      "2018-11-29 02:57:36,699 epoch 40 - iter 276/462 - loss 1.48573436\n",
      "2018-11-29 02:57:45,975 epoch 40 - iter 322/462 - loss 1.48384090\n",
      "2018-11-29 02:57:55,446 epoch 40 - iter 368/462 - loss 1.46915955\n",
      "2018-11-29 02:58:04,966 epoch 40 - iter 414/462 - loss 1.46053777\n",
      "2018-11-29 02:58:14,101 epoch 40 - iter 460/462 - loss 1.47087030\n",
      "2018-11-29 02:58:14,220 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 02:59:31,914 EPOCH 40: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 02:59:31,915 DEV : f-score 0.9294 - acc 0.9294 - tp 21657 - fp 1321 - fn 1970 - tn 21657\n",
      "2018-11-29 02:59:31,916 TEST: f-score 0.9294 - acc 0.9294 - tp 21657 - fp 1321 - fn 1970 - tn 21657\n",
      "2018-11-29 02:59:31,918 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-29 02:59:32,175 epoch 41 - iter 0/462 - loss 1.68082404\n",
      "2018-11-29 02:59:41,396 epoch 41 - iter 46/462 - loss 1.40200076\n",
      "2018-11-29 02:59:51,069 epoch 41 - iter 92/462 - loss 1.38966028\n",
      "2018-11-29 03:00:01,572 epoch 41 - iter 138/462 - loss 1.41319946\n",
      "2018-11-29 03:00:13,173 epoch 41 - iter 184/462 - loss 1.46273696\n",
      "2018-11-29 03:00:23,866 epoch 41 - iter 230/462 - loss 1.47201009\n",
      "2018-11-29 03:00:35,001 epoch 41 - iter 276/462 - loss 1.45911748\n",
      "2018-11-29 03:00:45,795 epoch 41 - iter 322/462 - loss 1.45582801\n",
      "2018-11-29 03:00:56,649 epoch 41 - iter 368/462 - loss 1.46093280\n",
      "2018-11-29 03:01:06,922 epoch 41 - iter 414/462 - loss 1.45282736\n",
      "2018-11-29 03:01:17,440 epoch 41 - iter 460/462 - loss 1.47506725\n",
      "2018-11-29 03:01:17,563 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:02:36,235 EPOCH 41: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 03:02:36,236 DEV : f-score 0.9295 - acc 0.9296 - tp 21544 - fp 1181 - fn 2083 - tn 21544\n",
      "2018-11-29 03:02:36,237 TEST: f-score 0.9295 - acc 0.9296 - tp 21544 - fp 1181 - fn 2083 - tn 21544\n",
      "2018-11-29 03:02:36,238 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:02:36,453 epoch 42 - iter 0/462 - loss 0.61832583\n",
      "2018-11-29 03:02:47,099 epoch 42 - iter 46/462 - loss 1.28933022\n",
      "2018-11-29 03:02:56,612 epoch 42 - iter 92/462 - loss 1.41513496\n",
      "2018-11-29 03:03:05,984 epoch 42 - iter 138/462 - loss 1.44981783\n",
      "2018-11-29 03:03:15,538 epoch 42 - iter 184/462 - loss 1.49386280\n",
      "2018-11-29 03:03:24,780 epoch 42 - iter 230/462 - loss 1.47753298\n",
      "2018-11-29 03:03:34,221 epoch 42 - iter 276/462 - loss 1.47345408\n",
      "2018-11-29 03:03:43,819 epoch 42 - iter 322/462 - loss 1.47904546\n",
      "2018-11-29 03:03:53,724 epoch 42 - iter 368/462 - loss 1.48944491\n",
      "2018-11-29 03:04:03,051 epoch 42 - iter 414/462 - loss 1.47451252\n",
      "2018-11-29 03:04:12,403 epoch 42 - iter 460/462 - loss 1.46446228\n",
      "2018-11-29 03:04:12,492 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:05:30,079 EPOCH 42: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 03:05:30,080 DEV : f-score 0.9320 - acc 0.9320 - tp 21671 - fp 1205 - fn 1956 - tn 21671\n",
      "2018-11-29 03:05:30,081 TEST: f-score 0.9320 - acc 0.9320 - tp 21671 - fp 1205 - fn 1956 - tn 21671\n",
      "2018-11-29 03:05:30,082 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:05:30,330 epoch 43 - iter 0/462 - loss 0.94969195\n",
      "2018-11-29 03:05:40,908 epoch 43 - iter 46/462 - loss 1.32819630\n",
      "2018-11-29 03:05:51,357 epoch 43 - iter 92/462 - loss 1.38107141\n",
      "2018-11-29 03:06:02,052 epoch 43 - iter 138/462 - loss 1.41818667\n",
      "2018-11-29 03:06:11,695 epoch 43 - iter 184/462 - loss 1.43228463\n",
      "2018-11-29 03:06:20,970 epoch 43 - iter 230/462 - loss 1.43250254\n",
      "2018-11-29 03:06:31,800 epoch 43 - iter 276/462 - loss 1.44492521\n",
      "2018-11-29 03:06:43,082 epoch 43 - iter 322/462 - loss 1.43877154\n",
      "2018-11-29 03:06:53,980 epoch 43 - iter 368/462 - loss 1.44293980\n",
      "2018-11-29 03:07:04,780 epoch 43 - iter 414/462 - loss 1.44199828\n",
      "2018-11-29 03:07:15,173 epoch 43 - iter 460/462 - loss 1.44747598\n",
      "2018-11-29 03:07:15,279 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:08:33,157 EPOCH 43: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 03:08:33,158 DEV : f-score 0.9293 - acc 0.9294 - tp 21527 - fp 1173 - fn 2100 - tn 21527\n",
      "2018-11-29 03:08:33,158 TEST: f-score 0.9293 - acc 0.9294 - tp 21527 - fp 1173 - fn 2100 - tn 21527\n",
      "2018-11-29 03:08:33,160 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:08:33,372 epoch 44 - iter 0/462 - loss 1.76680470\n",
      "2018-11-29 03:08:44,101 epoch 44 - iter 46/462 - loss 1.47779236\n",
      "2018-11-29 03:08:54,434 epoch 44 - iter 92/462 - loss 1.38806375\n",
      "2018-11-29 03:09:04,076 epoch 44 - iter 138/462 - loss 1.36994927\n",
      "2018-11-29 03:09:14,475 epoch 44 - iter 184/462 - loss 1.42274140\n",
      "2018-11-29 03:09:23,910 epoch 44 - iter 230/462 - loss 1.42095106\n",
      "2018-11-29 03:09:33,346 epoch 44 - iter 276/462 - loss 1.43421236\n",
      "2018-11-29 03:09:42,853 epoch 44 - iter 322/462 - loss 1.46614053\n",
      "2018-11-29 03:09:52,350 epoch 44 - iter 368/462 - loss 1.47180556\n",
      "2018-11-29 03:10:02,282 epoch 44 - iter 414/462 - loss 1.49057539\n",
      "2018-11-29 03:10:11,538 epoch 44 - iter 460/462 - loss 1.48421089\n",
      "2018-11-29 03:10:11,606 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:11:28,981 EPOCH 44: lr 0.1000 - bad epochs 1\n",
      "2018-11-29 03:11:28,982 DEV : f-score 0.9309 - acc 0.9309 - tp 21615 - fp 1197 - fn 2012 - tn 21615\n",
      "2018-11-29 03:11:28,983 TEST: f-score 0.9309 - acc 0.9309 - tp 21615 - fp 1197 - fn 2012 - tn 21615\n",
      "2018-11-29 03:11:28,984 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:11:29,217 epoch 45 - iter 0/462 - loss 1.38968861\n",
      "2018-11-29 03:11:38,496 epoch 45 - iter 46/462 - loss 1.32315734\n",
      "2018-11-29 03:11:47,994 epoch 45 - iter 92/462 - loss 1.34277248\n",
      "2018-11-29 03:11:58,415 epoch 45 - iter 138/462 - loss 1.36803383\n",
      "2018-11-29 03:12:09,686 epoch 45 - iter 184/462 - loss 1.42312612\n",
      "2018-11-29 03:12:20,695 epoch 45 - iter 230/462 - loss 1.41296455\n",
      "2018-11-29 03:12:31,372 epoch 45 - iter 276/462 - loss 1.40429875\n",
      "2018-11-29 03:12:41,082 epoch 45 - iter 322/462 - loss 1.43174594\n",
      "2018-11-29 03:12:50,509 epoch 45 - iter 368/462 - loss 1.44453887\n",
      "2018-11-29 03:12:59,751 epoch 45 - iter 414/462 - loss 1.43938414\n",
      "2018-11-29 03:13:09,005 epoch 45 - iter 460/462 - loss 1.44281867\n",
      "2018-11-29 03:13:09,143 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:14:26,712 EPOCH 45: lr 0.1000 - bad epochs 2\n",
      "2018-11-29 03:14:26,713 DEV : f-score 0.9341 - acc 0.9341 - tp 21699 - fp 1133 - fn 1928 - tn 21699\n",
      "2018-11-29 03:14:26,714 TEST: f-score 0.9341 - acc 0.9341 - tp 21699 - fp 1133 - fn 1928 - tn 21699\n",
      "2018-11-29 03:14:26,715 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:14:26,991 epoch 46 - iter 0/462 - loss 0.80157328\n",
      "2018-11-29 03:14:36,406 epoch 46 - iter 46/462 - loss 1.43356846\n",
      "2018-11-29 03:14:47,051 epoch 46 - iter 92/462 - loss 1.42334634\n",
      "2018-11-29 03:14:57,180 epoch 46 - iter 138/462 - loss 1.41432654\n",
      "2018-11-29 03:15:06,362 epoch 46 - iter 184/462 - loss 1.41502917\n",
      "2018-11-29 03:15:15,953 epoch 46 - iter 230/462 - loss 1.43393142\n",
      "2018-11-29 03:15:26,636 epoch 46 - iter 276/462 - loss 1.44971967\n",
      "2018-11-29 03:15:35,903 epoch 46 - iter 322/462 - loss 1.44554928\n",
      "2018-11-29 03:15:45,212 epoch 46 - iter 368/462 - loss 1.45054964\n",
      "2018-11-29 03:15:54,543 epoch 46 - iter 414/462 - loss 1.44415400\n",
      "2018-11-29 03:16:03,966 epoch 46 - iter 460/462 - loss 1.44082913\n",
      "2018-11-29 03:16:04,077 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:17:21,798 EPOCH 46: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 03:17:21,799 DEV : f-score 0.9335 - acc 0.9335 - tp 21631 - fp 1086 - fn 1996 - tn 21631\n",
      "2018-11-29 03:17:21,799 TEST: f-score 0.9335 - acc 0.9335 - tp 21631 - fp 1086 - fn 1996 - tn 21631\n",
      "2018-11-29 03:17:21,800 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:17:22,010 epoch 47 - iter 0/462 - loss 2.04919291\n",
      "2018-11-29 03:17:31,036 epoch 47 - iter 46/462 - loss 1.42328303\n",
      "2018-11-29 03:17:40,632 epoch 47 - iter 92/462 - loss 1.41848365\n",
      "2018-11-29 03:17:50,381 epoch 47 - iter 138/462 - loss 1.42775387\n",
      "2018-11-29 03:17:59,772 epoch 47 - iter 184/462 - loss 1.42497992\n",
      "2018-11-29 03:18:09,269 epoch 47 - iter 230/462 - loss 1.42729359\n",
      "2018-11-29 03:18:18,571 epoch 47 - iter 276/462 - loss 1.41254536\n",
      "2018-11-29 03:18:27,957 epoch 47 - iter 322/462 - loss 1.41740346\n",
      "2018-11-29 03:18:37,275 epoch 47 - iter 368/462 - loss 1.41416530\n",
      "2018-11-29 03:18:46,761 epoch 47 - iter 414/462 - loss 1.41734336\n",
      "2018-11-29 03:18:56,257 epoch 47 - iter 460/462 - loss 1.42401831\n",
      "2018-11-29 03:18:56,385 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-29 03:20:14,055 EPOCH 47: lr 0.1000 - bad epochs 1\n",
      "2018-11-29 03:20:14,056 DEV : f-score 0.9347 - acc 0.9347 - tp 21728 - fp 1137 - fn 1899 - tn 21728\n",
      "2018-11-29 03:20:14,057 TEST: f-score 0.9347 - acc 0.9347 - tp 21728 - fp 1137 - fn 1899 - tn 21728\n",
      "2018-11-29 03:20:14,057 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:20:14,293 epoch 48 - iter 0/462 - loss 1.27451491\n",
      "2018-11-29 03:20:23,647 epoch 48 - iter 46/462 - loss 1.39793575\n",
      "2018-11-29 03:20:33,273 epoch 48 - iter 92/462 - loss 1.40439285\n",
      "2018-11-29 03:20:42,760 epoch 48 - iter 138/462 - loss 1.40799380\n",
      "2018-11-29 03:20:52,140 epoch 48 - iter 184/462 - loss 1.41983762\n",
      "2018-11-29 03:21:01,876 epoch 48 - iter 230/462 - loss 1.44011063\n",
      "2018-11-29 03:21:10,953 epoch 48 - iter 276/462 - loss 1.42280271\n",
      "2018-11-29 03:21:20,174 epoch 48 - iter 322/462 - loss 1.41751124\n",
      "2018-11-29 03:21:29,193 epoch 48 - iter 368/462 - loss 1.40365341\n",
      "2018-11-29 03:21:38,612 epoch 48 - iter 414/462 - loss 1.41965387\n",
      "2018-11-29 03:21:48,805 epoch 48 - iter 460/462 - loss 1.41778659\n",
      "2018-11-29 03:21:48,934 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:23:06,250 EPOCH 48: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 03:23:06,251 DEV : f-score 0.9325 - acc 0.9325 - tp 21682 - fp 1196 - fn 1945 - tn 21682\n",
      "2018-11-29 03:23:06,252 TEST: f-score 0.9325 - acc 0.9325 - tp 21682 - fp 1196 - fn 1945 - tn 21682\n",
      "2018-11-29 03:23:06,252 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:23:06,493 epoch 49 - iter 0/462 - loss 1.15924287\n",
      "2018-11-29 03:23:15,740 epoch 49 - iter 46/462 - loss 1.50939445\n",
      "2018-11-29 03:23:25,101 epoch 49 - iter 92/462 - loss 1.51027071\n",
      "2018-11-29 03:23:34,625 epoch 49 - iter 138/462 - loss 1.52296830\n",
      "2018-11-29 03:23:44,235 epoch 49 - iter 184/462 - loss 1.47522721\n",
      "2018-11-29 03:23:53,429 epoch 49 - iter 230/462 - loss 1.47663305\n",
      "2018-11-29 03:24:03,738 epoch 49 - iter 276/462 - loss 1.44996611\n",
      "2018-11-29 03:24:13,508 epoch 49 - iter 322/462 - loss 1.42757365\n",
      "2018-11-29 03:24:22,927 epoch 49 - iter 368/462 - loss 1.43677681\n",
      "2018-11-29 03:24:32,224 epoch 49 - iter 414/462 - loss 1.42364802\n",
      "2018-11-29 03:24:41,588 epoch 49 - iter 460/462 - loss 1.43066449\n",
      "2018-11-29 03:24:41,695 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:25:59,358 EPOCH 49: lr 0.1000 - bad epochs 1\n",
      "2018-11-29 03:25:59,358 DEV : f-score 0.9348 - acc 0.9348 - tp 21772 - fp 1181 - fn 1855 - tn 21772\n",
      "2018-11-29 03:25:59,359 TEST: f-score 0.9348 - acc 0.9348 - tp 21772 - fp 1181 - fn 1855 - tn 21772\n",
      "2018-11-29 03:25:59,360 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:25:59,615 epoch 50 - iter 0/462 - loss 0.99685574\n",
      "2018-11-29 03:26:09,883 epoch 50 - iter 46/462 - loss 1.30802560\n",
      "2018-11-29 03:26:20,877 epoch 50 - iter 92/462 - loss 1.36158545\n",
      "2018-11-29 03:26:31,993 epoch 50 - iter 138/462 - loss 1.42569681\n",
      "2018-11-29 03:26:42,490 epoch 50 - iter 184/462 - loss 1.40303012\n",
      "2018-11-29 03:26:53,735 epoch 50 - iter 230/462 - loss 1.42726804\n",
      "2018-11-29 03:27:04,480 epoch 50 - iter 276/462 - loss 1.46116694\n",
      "2018-11-29 03:27:14,434 epoch 50 - iter 322/462 - loss 1.46732782\n",
      "2018-11-29 03:27:23,942 epoch 50 - iter 368/462 - loss 1.45970341\n",
      "2018-11-29 03:27:33,668 epoch 50 - iter 414/462 - loss 1.44564687\n",
      "2018-11-29 03:27:42,682 epoch 50 - iter 460/462 - loss 1.44335167\n",
      "2018-11-29 03:27:42,831 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:29:00,764 EPOCH 50: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 03:29:00,765 DEV : f-score 0.9348 - acc 0.9349 - tp 21697 - fp 1094 - fn 1930 - tn 21697\n",
      "2018-11-29 03:29:00,765 TEST: f-score 0.9348 - acc 0.9349 - tp 21697 - fp 1094 - fn 1930 - tn 21697\n",
      "2018-11-29 03:29:00,766 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:29:00,947 epoch 51 - iter 0/462 - loss 1.12769306\n",
      "2018-11-29 03:29:10,198 epoch 51 - iter 46/462 - loss 1.31126153\n",
      "2018-11-29 03:29:19,601 epoch 51 - iter 92/462 - loss 1.37335726\n",
      "2018-11-29 03:29:29,371 epoch 51 - iter 138/462 - loss 1.40635866\n",
      "2018-11-29 03:29:38,614 epoch 51 - iter 184/462 - loss 1.41672847\n",
      "2018-11-29 03:29:47,562 epoch 51 - iter 230/462 - loss 1.39109098\n",
      "2018-11-29 03:29:57,104 epoch 51 - iter 276/462 - loss 1.39256784\n",
      "2018-11-29 03:30:06,618 epoch 51 - iter 322/462 - loss 1.41457091\n",
      "2018-11-29 03:30:16,300 epoch 51 - iter 368/462 - loss 1.42513816\n",
      "2018-11-29 03:30:25,615 epoch 51 - iter 414/462 - loss 1.42107852\n",
      "2018-11-29 03:30:35,111 epoch 51 - iter 460/462 - loss 1.42221060\n",
      "2018-11-29 03:30:35,237 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:31:53,037 EPOCH 51: lr 0.1000 - bad epochs 1\n",
      "2018-11-29 03:31:53,037 DEV : f-score 0.9350 - acc 0.9350 - tp 21803 - fp 1206 - fn 1824 - tn 21803\n",
      "2018-11-29 03:31:53,038 TEST: f-score 0.9350 - acc 0.9350 - tp 21803 - fp 1206 - fn 1824 - tn 21803\n",
      "2018-11-29 03:31:53,039 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:31:53,267 epoch 52 - iter 0/462 - loss 2.85263729\n",
      "2018-11-29 03:32:02,860 epoch 52 - iter 46/462 - loss 1.48320807\n",
      "2018-11-29 03:32:12,235 epoch 52 - iter 92/462 - loss 1.47042764\n",
      "2018-11-29 03:32:21,546 epoch 52 - iter 138/462 - loss 1.48626413\n",
      "2018-11-29 03:32:30,473 epoch 52 - iter 184/462 - loss 1.46025826\n",
      "2018-11-29 03:32:39,506 epoch 52 - iter 230/462 - loss 1.42222951\n",
      "2018-11-29 03:32:49,359 epoch 52 - iter 276/462 - loss 1.43689672\n",
      "2018-11-29 03:33:00,284 epoch 52 - iter 322/462 - loss 1.43476540\n",
      "2018-11-29 03:33:11,356 epoch 52 - iter 368/462 - loss 1.44560046\n",
      "2018-11-29 03:33:21,299 epoch 52 - iter 414/462 - loss 1.45235344\n",
      "2018-11-29 03:33:30,827 epoch 52 - iter 460/462 - loss 1.44899621\n",
      "2018-11-29 03:33:30,893 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:34:47,932 EPOCH 52: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 03:34:47,933 DEV : f-score 0.9364 - acc 0.9364 - tp 21731 - fp 1058 - fn 1896 - tn 21731\n",
      "2018-11-29 03:34:47,934 TEST: f-score 0.9364 - acc 0.9364 - tp 21731 - fp 1058 - fn 1896 - tn 21731\n",
      "2018-11-29 03:34:47,935 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:34:48,187 epoch 53 - iter 0/462 - loss 1.59259844\n",
      "2018-11-29 03:34:57,079 epoch 53 - iter 46/462 - loss 1.37964414\n",
      "2018-11-29 03:35:06,661 epoch 53 - iter 92/462 - loss 1.33896254\n",
      "2018-11-29 03:35:15,912 epoch 53 - iter 138/462 - loss 1.37948434\n",
      "2018-11-29 03:35:25,262 epoch 53 - iter 184/462 - loss 1.38433597\n",
      "2018-11-29 03:35:34,572 epoch 53 - iter 230/462 - loss 1.38529741\n",
      "2018-11-29 03:35:44,107 epoch 53 - iter 276/462 - loss 1.43532270\n",
      "2018-11-29 03:35:53,422 epoch 53 - iter 322/462 - loss 1.44146837\n",
      "2018-11-29 03:36:03,114 epoch 53 - iter 368/462 - loss 1.43398198\n",
      "2018-11-29 03:36:12,454 epoch 53 - iter 414/462 - loss 1.43418635\n",
      "2018-11-29 03:36:22,040 epoch 53 - iter 460/462 - loss 1.42809965\n",
      "2018-11-29 03:36:22,144 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:37:39,721 EPOCH 53: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 03:37:39,722 DEV : f-score 0.9334 - acc 0.9334 - tp 21817 - fp 1304 - fn 1810 - tn 21817\n",
      "2018-11-29 03:37:39,722 TEST: f-score 0.9334 - acc 0.9334 - tp 21817 - fp 1304 - fn 1810 - tn 21817\n",
      "2018-11-29 03:37:39,723 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:37:39,935 epoch 54 - iter 0/462 - loss 1.20112228\n",
      "2018-11-29 03:37:49,181 epoch 54 - iter 46/462 - loss 1.39347941\n",
      "2018-11-29 03:37:58,641 epoch 54 - iter 92/462 - loss 1.39446238\n",
      "2018-11-29 03:38:07,950 epoch 54 - iter 138/462 - loss 1.41975305\n",
      "2018-11-29 03:38:17,265 epoch 54 - iter 184/462 - loss 1.40119163\n",
      "2018-11-29 03:38:27,008 epoch 54 - iter 230/462 - loss 1.38201353\n",
      "2018-11-29 03:38:36,401 epoch 54 - iter 276/462 - loss 1.37533067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-29 03:38:45,626 epoch 54 - iter 322/462 - loss 1.39169016\n",
      "2018-11-29 03:38:54,984 epoch 54 - iter 368/462 - loss 1.39534549\n",
      "2018-11-29 03:39:04,400 epoch 54 - iter 414/462 - loss 1.40397155\n",
      "2018-11-29 03:39:13,820 epoch 54 - iter 460/462 - loss 1.41482110\n",
      "2018-11-29 03:39:13,959 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:40:31,560 EPOCH 54: lr 0.1000 - bad epochs 1\n",
      "2018-11-29 03:40:31,560 DEV : f-score 0.9370 - acc 0.9369 - tp 21782 - fp 1087 - fn 1845 - tn 21782\n",
      "2018-11-29 03:40:31,561 TEST: f-score 0.9370 - acc 0.9369 - tp 21782 - fp 1087 - fn 1845 - tn 21782\n",
      "2018-11-29 03:40:31,562 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:40:31,809 epoch 55 - iter 0/462 - loss 1.64746428\n",
      "2018-11-29 03:40:41,345 epoch 55 - iter 46/462 - loss 1.56447826\n",
      "2018-11-29 03:40:50,543 epoch 55 - iter 92/462 - loss 1.43306624\n",
      "2018-11-29 03:41:00,016 epoch 55 - iter 138/462 - loss 1.40098450\n",
      "2018-11-29 03:41:09,532 epoch 55 - iter 184/462 - loss 1.38873810\n",
      "2018-11-29 03:41:18,748 epoch 55 - iter 230/462 - loss 1.37390911\n",
      "2018-11-29 03:41:28,183 epoch 55 - iter 276/462 - loss 1.40971799\n",
      "2018-11-29 03:41:37,679 epoch 55 - iter 322/462 - loss 1.42097419\n",
      "2018-11-29 03:41:47,132 epoch 55 - iter 368/462 - loss 1.41566294\n",
      "2018-11-29 03:41:56,933 epoch 55 - iter 414/462 - loss 1.41123425\n",
      "2018-11-29 03:42:06,386 epoch 55 - iter 460/462 - loss 1.41877778\n",
      "2018-11-29 03:42:06,523 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:43:24,403 EPOCH 55: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 03:43:24,404 DEV : f-score 0.9381 - acc 0.9381 - tp 21917 - fp 1180 - fn 1710 - tn 21917\n",
      "2018-11-29 03:43:24,405 TEST: f-score 0.9381 - acc 0.9381 - tp 21917 - fp 1180 - fn 1710 - tn 21917\n",
      "2018-11-29 03:43:24,406 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:43:24,619 epoch 56 - iter 0/462 - loss 2.23082089\n",
      "2018-11-29 03:43:33,953 epoch 56 - iter 46/462 - loss 1.36624500\n",
      "2018-11-29 03:43:43,331 epoch 56 - iter 92/462 - loss 1.39977786\n",
      "2018-11-29 03:43:53,468 epoch 56 - iter 138/462 - loss 1.38436204\n",
      "2018-11-29 03:44:02,863 epoch 56 - iter 184/462 - loss 1.37175209\n",
      "2018-11-29 03:44:12,763 epoch 56 - iter 230/462 - loss 1.36894262\n",
      "2018-11-29 03:44:22,084 epoch 56 - iter 276/462 - loss 1.37013234\n",
      "2018-11-29 03:44:31,372 epoch 56 - iter 322/462 - loss 1.36525704\n",
      "2018-11-29 03:44:40,945 epoch 56 - iter 368/462 - loss 1.38897305\n",
      "2018-11-29 03:44:50,408 epoch 56 - iter 414/462 - loss 1.38833919\n",
      "2018-11-29 03:44:59,678 epoch 56 - iter 460/462 - loss 1.41036166\n",
      "2018-11-29 03:44:59,812 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:46:17,386 EPOCH 56: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 03:46:17,387 DEV : f-score 0.9372 - acc 0.9372 - tp 21723 - fp 1008 - fn 1904 - tn 21723\n",
      "2018-11-29 03:46:17,388 TEST: f-score 0.9372 - acc 0.9372 - tp 21723 - fp 1008 - fn 1904 - tn 21723\n",
      "2018-11-29 03:46:17,389 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:46:17,621 epoch 57 - iter 0/462 - loss 1.97372937\n",
      "2018-11-29 03:46:28,001 epoch 57 - iter 46/462 - loss 1.36125940\n",
      "2018-11-29 03:46:38,805 epoch 57 - iter 92/462 - loss 1.44222911\n",
      "2018-11-29 03:46:49,566 epoch 57 - iter 138/462 - loss 1.41465403\n",
      "2018-11-29 03:47:00,348 epoch 57 - iter 184/462 - loss 1.42165558\n",
      "2018-11-29 03:47:10,503 epoch 57 - iter 230/462 - loss 1.38505812\n",
      "2018-11-29 03:47:20,975 epoch 57 - iter 276/462 - loss 1.37221026\n",
      "2018-11-29 03:47:31,757 epoch 57 - iter 322/462 - loss 1.37744562\n",
      "2018-11-29 03:47:42,504 epoch 57 - iter 368/462 - loss 1.38800244\n",
      "2018-11-29 03:47:53,187 epoch 57 - iter 414/462 - loss 1.38325739\n",
      "2018-11-29 03:48:04,503 epoch 57 - iter 460/462 - loss 1.39125278\n",
      "2018-11-29 03:48:04,636 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:49:21,993 EPOCH 57: lr 0.1000 - bad epochs 1\n",
      "2018-11-29 03:49:21,994 DEV : f-score 0.9371 - acc 0.9371 - tp 21859 - fp 1167 - fn 1768 - tn 21859\n",
      "2018-11-29 03:49:21,994 TEST: f-score 0.9371 - acc 0.9371 - tp 21859 - fp 1167 - fn 1768 - tn 21859\n",
      "2018-11-29 03:49:21,996 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:49:22,233 epoch 58 - iter 0/462 - loss 1.29871774\n",
      "2018-11-29 03:49:32,208 epoch 58 - iter 46/462 - loss 1.35932476\n",
      "2018-11-29 03:49:41,515 epoch 58 - iter 92/462 - loss 1.35514202\n",
      "2018-11-29 03:49:51,111 epoch 58 - iter 138/462 - loss 1.38722921\n",
      "2018-11-29 03:50:00,476 epoch 58 - iter 184/462 - loss 1.37711510\n",
      "2018-11-29 03:50:10,039 epoch 58 - iter 230/462 - loss 1.38365373\n",
      "2018-11-29 03:50:19,372 epoch 58 - iter 276/462 - loss 1.36861038\n",
      "2018-11-29 03:50:28,607 epoch 58 - iter 322/462 - loss 1.35717153\n",
      "2018-11-29 03:50:37,647 epoch 58 - iter 368/462 - loss 1.36306157\n",
      "2018-11-29 03:50:47,013 epoch 58 - iter 414/462 - loss 1.37242220\n",
      "2018-11-29 03:50:56,667 epoch 58 - iter 460/462 - loss 1.38851661\n",
      "2018-11-29 03:50:56,768 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:52:14,496 EPOCH 58: lr 0.1000 - bad epochs 2\n",
      "2018-11-29 03:52:14,497 DEV : f-score 0.9394 - acc 0.9394 - tp 21860 - fp 1053 - fn 1767 - tn 21860\n",
      "2018-11-29 03:52:14,497 TEST: f-score 0.9394 - acc 0.9394 - tp 21860 - fp 1053 - fn 1767 - tn 21860\n",
      "2018-11-29 03:52:14,498 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:52:14,697 epoch 59 - iter 0/462 - loss 0.80009496\n",
      "2018-11-29 03:52:23,901 epoch 59 - iter 46/462 - loss 1.23857658\n",
      "2018-11-29 03:52:33,454 epoch 59 - iter 92/462 - loss 1.32711549\n",
      "2018-11-29 03:52:42,833 epoch 59 - iter 138/462 - loss 1.36512460\n",
      "2018-11-29 03:52:52,373 epoch 59 - iter 184/462 - loss 1.37234019\n",
      "2018-11-29 03:53:01,436 epoch 59 - iter 230/462 - loss 1.34602737\n",
      "2018-11-29 03:53:10,669 epoch 59 - iter 276/462 - loss 1.34118988\n",
      "2018-11-29 03:53:19,917 epoch 59 - iter 322/462 - loss 1.35779941\n",
      "2018-11-29 03:53:29,943 epoch 59 - iter 368/462 - loss 1.36838261\n",
      "2018-11-29 03:53:39,027 epoch 59 - iter 414/462 - loss 1.38217460\n",
      "2018-11-29 03:53:48,831 epoch 59 - iter 460/462 - loss 1.38155111\n",
      "2018-11-29 03:53:48,963 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:55:06,728 EPOCH 59: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 03:55:06,728 DEV : f-score 0.9365 - acc 0.9365 - tp 21774 - fp 1102 - fn 1853 - tn 21774\n",
      "2018-11-29 03:55:06,729 TEST: f-score 0.9365 - acc 0.9365 - tp 21774 - fp 1102 - fn 1853 - tn 21774\n",
      "2018-11-29 03:55:06,730 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:55:06,912 epoch 60 - iter 0/462 - loss 2.00017762\n",
      "2018-11-29 03:55:16,352 epoch 60 - iter 46/462 - loss 1.36301138\n",
      "2018-11-29 03:55:26,143 epoch 60 - iter 92/462 - loss 1.44959361\n",
      "2018-11-29 03:55:35,520 epoch 60 - iter 138/462 - loss 1.43452333\n",
      "2018-11-29 03:55:44,583 epoch 60 - iter 184/462 - loss 1.42371882\n",
      "2018-11-29 03:55:53,962 epoch 60 - iter 230/462 - loss 1.41721380\n",
      "2018-11-29 03:56:03,381 epoch 60 - iter 276/462 - loss 1.41974654\n",
      "2018-11-29 03:56:12,760 epoch 60 - iter 322/462 - loss 1.41905454\n",
      "2018-11-29 03:56:22,432 epoch 60 - iter 368/462 - loss 1.42326430\n",
      "2018-11-29 03:56:31,823 epoch 60 - iter 414/462 - loss 1.41800919\n",
      "2018-11-29 03:56:41,330 epoch 60 - iter 460/462 - loss 1.41973935\n",
      "2018-11-29 03:56:41,459 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:57:58,976 EPOCH 60: lr 0.1000 - bad epochs 1\n",
      "2018-11-29 03:57:58,976 DEV : f-score 0.9375 - acc 0.9376 - tp 21790 - fp 1064 - fn 1837 - tn 21790\n",
      "2018-11-29 03:57:58,977 TEST: f-score 0.9375 - acc 0.9376 - tp 21790 - fp 1064 - fn 1837 - tn 21790\n",
      "2018-11-29 03:57:58,978 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 03:57:59,171 epoch 61 - iter 0/462 - loss 1.84700644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-29 03:58:08,945 epoch 61 - iter 46/462 - loss 1.40949791\n",
      "2018-11-29 03:58:18,365 epoch 61 - iter 92/462 - loss 1.45972544\n",
      "2018-11-29 03:58:27,560 epoch 61 - iter 138/462 - loss 1.43738078\n",
      "2018-11-29 03:58:37,063 epoch 61 - iter 184/462 - loss 1.40941699\n",
      "2018-11-29 03:58:46,321 epoch 61 - iter 230/462 - loss 1.42545866\n",
      "2018-11-29 03:58:55,325 epoch 61 - iter 276/462 - loss 1.42078351\n",
      "2018-11-29 03:59:04,522 epoch 61 - iter 322/462 - loss 1.41279453\n",
      "2018-11-29 03:59:13,829 epoch 61 - iter 368/462 - loss 1.38619155\n",
      "2018-11-29 03:59:23,138 epoch 61 - iter 414/462 - loss 1.38823280\n",
      "2018-11-29 03:59:33,399 epoch 61 - iter 460/462 - loss 1.37746820\n",
      "2018-11-29 03:59:33,566 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:00:51,520 EPOCH 61: lr 0.1000 - bad epochs 2\n",
      "2018-11-29 04:00:51,521 DEV : f-score 0.9404 - acc 0.9404 - tp 21965 - fp 1123 - fn 1662 - tn 21965\n",
      "2018-11-29 04:00:51,522 TEST: f-score 0.9404 - acc 0.9404 - tp 21965 - fp 1123 - fn 1662 - tn 21965\n",
      "2018-11-29 04:00:51,523 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:00:51,765 epoch 62 - iter 0/462 - loss 1.02383208\n",
      "2018-11-29 04:01:02,903 epoch 62 - iter 46/462 - loss 1.33714295\n",
      "2018-11-29 04:01:13,290 epoch 62 - iter 92/462 - loss 1.33616236\n",
      "2018-11-29 04:01:23,882 epoch 62 - iter 138/462 - loss 1.33860408\n",
      "2018-11-29 04:01:34,121 epoch 62 - iter 184/462 - loss 1.32679194\n",
      "2018-11-29 04:01:44,977 epoch 62 - iter 230/462 - loss 1.32950205\n",
      "2018-11-29 04:01:55,645 epoch 62 - iter 276/462 - loss 1.33832758\n",
      "2018-11-29 04:02:05,209 epoch 62 - iter 322/462 - loss 1.35186390\n",
      "2018-11-29 04:02:14,740 epoch 62 - iter 368/462 - loss 1.35830167\n",
      "2018-11-29 04:02:24,205 epoch 62 - iter 414/462 - loss 1.36848754\n",
      "2018-11-29 04:02:33,561 epoch 62 - iter 460/462 - loss 1.38235705\n",
      "2018-11-29 04:02:33,638 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:03:50,802 EPOCH 62: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 04:03:50,803 DEV : f-score 0.9401 - acc 0.9400 - tp 21944 - fp 1116 - fn 1683 - tn 21944\n",
      "2018-11-29 04:03:50,803 TEST: f-score 0.9401 - acc 0.9400 - tp 21944 - fp 1116 - fn 1683 - tn 21944\n",
      "2018-11-29 04:03:50,804 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:03:51,134 epoch 63 - iter 0/462 - loss 2.21466231\n",
      "2018-11-29 04:04:02,225 epoch 63 - iter 46/462 - loss 1.53843792\n",
      "2018-11-29 04:04:12,400 epoch 63 - iter 92/462 - loss 1.48101738\n",
      "2018-11-29 04:04:22,762 epoch 63 - iter 138/462 - loss 1.45769947\n",
      "2018-11-29 04:04:34,220 epoch 63 - iter 184/462 - loss 1.46202950\n",
      "2018-11-29 04:04:45,161 epoch 63 - iter 230/462 - loss 1.42741021\n",
      "2018-11-29 04:04:56,040 epoch 63 - iter 276/462 - loss 1.39782411\n",
      "2018-11-29 04:05:06,775 epoch 63 - iter 322/462 - loss 1.39798369\n",
      "2018-11-29 04:05:17,184 epoch 63 - iter 368/462 - loss 1.38803693\n",
      "2018-11-29 04:05:26,181 epoch 63 - iter 414/462 - loss 1.37912886\n",
      "2018-11-29 04:05:36,085 epoch 63 - iter 460/462 - loss 1.38366490\n",
      "2018-11-29 04:05:36,237 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:06:53,747 EPOCH 63: lr 0.1000 - bad epochs 1\n",
      "2018-11-29 04:06:53,748 DEV : f-score 0.9396 - acc 0.9395 - tp 21812 - fp 993 - fn 1815 - tn 21812\n",
      "2018-11-29 04:06:53,748 TEST: f-score 0.9396 - acc 0.9395 - tp 21812 - fp 993 - fn 1815 - tn 21812\n",
      "2018-11-29 04:06:53,749 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:06:53,975 epoch 64 - iter 0/462 - loss 1.46897650\n",
      "2018-11-29 04:07:04,071 epoch 64 - iter 46/462 - loss 1.31384290\n",
      "2018-11-29 04:07:14,867 epoch 64 - iter 92/462 - loss 1.37004774\n",
      "2018-11-29 04:07:25,466 epoch 64 - iter 138/462 - loss 1.37925358\n",
      "2018-11-29 04:07:35,412 epoch 64 - iter 184/462 - loss 1.37582487\n",
      "2018-11-29 04:07:44,759 epoch 64 - iter 230/462 - loss 1.40977357\n",
      "2018-11-29 04:07:54,471 epoch 64 - iter 276/462 - loss 1.40538051\n",
      "2018-11-29 04:08:03,959 epoch 64 - iter 322/462 - loss 1.39591942\n",
      "2018-11-29 04:08:13,544 epoch 64 - iter 368/462 - loss 1.38740622\n",
      "2018-11-29 04:08:22,881 epoch 64 - iter 414/462 - loss 1.39269182\n",
      "2018-11-29 04:08:32,253 epoch 64 - iter 460/462 - loss 1.39901989\n",
      "2018-11-29 04:08:32,332 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:09:49,387 EPOCH 64: lr 0.1000 - bad epochs 2\n",
      "2018-11-29 04:09:49,388 DEV : f-score 0.9402 - acc 0.9403 - tp 21896 - fp 1051 - fn 1731 - tn 21896\n",
      "2018-11-29 04:09:49,388 TEST: f-score 0.9402 - acc 0.9403 - tp 21896 - fp 1051 - fn 1731 - tn 21896\n",
      "2018-11-29 04:09:49,389 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:09:49,623 epoch 65 - iter 0/462 - loss 0.89061278\n",
      "2018-11-29 04:10:00,358 epoch 65 - iter 46/462 - loss 1.40181331\n",
      "2018-11-29 04:10:10,800 epoch 65 - iter 92/462 - loss 1.34781434\n",
      "2018-11-29 04:10:20,461 epoch 65 - iter 138/462 - loss 1.34118103\n",
      "2018-11-29 04:10:29,975 epoch 65 - iter 184/462 - loss 1.35678819\n",
      "2018-11-29 04:10:39,484 epoch 65 - iter 230/462 - loss 1.36344354\n",
      "2018-11-29 04:10:48,883 epoch 65 - iter 276/462 - loss 1.36245283\n",
      "2018-11-29 04:10:58,174 epoch 65 - iter 322/462 - loss 1.37864008\n",
      "2018-11-29 04:11:07,770 epoch 65 - iter 368/462 - loss 1.40098470\n",
      "2018-11-29 04:11:16,809 epoch 65 - iter 414/462 - loss 1.38864894\n",
      "2018-11-29 04:11:26,332 epoch 65 - iter 460/462 - loss 1.38417770\n",
      "2018-11-29 04:11:26,451 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:12:45,398 EPOCH 65: lr 0.1000 - bad epochs 3\n",
      "2018-11-29 04:12:45,399 DEV : f-score 0.9421 - acc 0.9420 - tp 21944 - fp 1017 - fn 1683 - tn 21944\n",
      "2018-11-29 04:12:45,399 TEST: f-score 0.9421 - acc 0.9420 - tp 21944 - fp 1017 - fn 1683 - tn 21944\n",
      "2018-11-29 04:12:45,400 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:12:45,619 epoch 66 - iter 0/462 - loss 1.12646306\n",
      "2018-11-29 04:12:55,054 epoch 66 - iter 46/462 - loss 1.37721602\n",
      "2018-11-29 04:13:04,105 epoch 66 - iter 92/462 - loss 1.36594235\n",
      "2018-11-29 04:13:13,442 epoch 66 - iter 138/462 - loss 1.35154281\n",
      "2018-11-29 04:13:22,930 epoch 66 - iter 184/462 - loss 1.35551839\n",
      "2018-11-29 04:13:32,546 epoch 66 - iter 230/462 - loss 1.36760237\n",
      "2018-11-29 04:13:41,989 epoch 66 - iter 276/462 - loss 1.34738469\n",
      "2018-11-29 04:13:51,341 epoch 66 - iter 322/462 - loss 1.35944905\n",
      "2018-11-29 04:14:01,957 epoch 66 - iter 368/462 - loss 1.35910180\n",
      "2018-11-29 04:14:12,718 epoch 66 - iter 414/462 - loss 1.37246126\n",
      "2018-11-29 04:14:23,267 epoch 66 - iter 460/462 - loss 1.36897636\n",
      "2018-11-29 04:14:23,430 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:15:41,012 EPOCH 66: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 04:15:41,012 DEV : f-score 0.9421 - acc 0.9421 - tp 21962 - fp 1036 - fn 1665 - tn 21962\n",
      "2018-11-29 04:15:41,013 TEST: f-score 0.9421 - acc 0.9421 - tp 21962 - fp 1036 - fn 1665 - tn 21962\n",
      "2018-11-29 04:15:41,014 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:15:41,238 epoch 67 - iter 0/462 - loss 1.04394734\n",
      "2018-11-29 04:15:51,203 epoch 67 - iter 46/462 - loss 1.24544419\n",
      "2018-11-29 04:16:00,693 epoch 67 - iter 92/462 - loss 1.34623296\n",
      "2018-11-29 04:16:09,944 epoch 67 - iter 138/462 - loss 1.35718225\n",
      "2018-11-29 04:16:19,403 epoch 67 - iter 184/462 - loss 1.34920934\n",
      "2018-11-29 04:16:28,858 epoch 67 - iter 230/462 - loss 1.35354753\n",
      "2018-11-29 04:16:38,089 epoch 67 - iter 276/462 - loss 1.36460011\n",
      "2018-11-29 04:16:47,382 epoch 67 - iter 322/462 - loss 1.35855397\n",
      "2018-11-29 04:16:56,843 epoch 67 - iter 368/462 - loss 1.35197190\n",
      "2018-11-29 04:17:06,376 epoch 67 - iter 414/462 - loss 1.35496328\n",
      "2018-11-29 04:17:15,985 epoch 67 - iter 460/462 - loss 1.37078170\n",
      "2018-11-29 04:17:16,053 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:18:33,074 EPOCH 67: lr 0.1000 - bad epochs 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-29 04:18:33,075 DEV : f-score 0.9427 - acc 0.9427 - tp 22028 - fp 1077 - fn 1599 - tn 22028\n",
      "2018-11-29 04:18:33,076 TEST: f-score 0.9427 - acc 0.9427 - tp 22028 - fp 1077 - fn 1599 - tn 22028\n",
      "2018-11-29 04:18:33,076 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:18:33,354 epoch 68 - iter 0/462 - loss 1.77425468\n",
      "2018-11-29 04:18:42,596 epoch 68 - iter 46/462 - loss 1.23356190\n",
      "2018-11-29 04:18:51,938 epoch 68 - iter 92/462 - loss 1.32085868\n",
      "2018-11-29 04:19:01,256 epoch 68 - iter 138/462 - loss 1.29183478\n",
      "2018-11-29 04:19:10,699 epoch 68 - iter 184/462 - loss 1.32344739\n",
      "2018-11-29 04:19:20,358 epoch 68 - iter 230/462 - loss 1.34103659\n",
      "2018-11-29 04:19:29,810 epoch 68 - iter 276/462 - loss 1.34023891\n",
      "2018-11-29 04:19:39,143 epoch 68 - iter 322/462 - loss 1.32954936\n",
      "2018-11-29 04:19:48,624 epoch 68 - iter 368/462 - loss 1.33658722\n",
      "2018-11-29 04:19:58,100 epoch 68 - iter 414/462 - loss 1.35008624\n",
      "2018-11-29 04:20:07,327 epoch 68 - iter 460/462 - loss 1.34566381\n",
      "2018-11-29 04:20:07,467 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:21:25,143 EPOCH 68: lr 0.1000 - bad epochs 0\n",
      "2018-11-29 04:21:25,144 DEV : f-score 0.9411 - acc 0.9411 - tp 21969 - fp 1091 - fn 1658 - tn 21969\n",
      "2018-11-29 04:21:25,144 TEST: f-score 0.9411 - acc 0.9411 - tp 21969 - fp 1091 - fn 1658 - tn 21969\n",
      "2018-11-29 04:21:25,146 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:21:25,417 epoch 69 - iter 0/462 - loss 0.88634306\n",
      "2018-11-29 04:21:34,898 epoch 69 - iter 46/462 - loss 1.24293551\n",
      "2018-11-29 04:21:45,087 epoch 69 - iter 92/462 - loss 1.34100491\n",
      "2018-11-29 04:21:55,251 epoch 69 - iter 138/462 - loss 1.36354722\n",
      "2018-11-29 04:22:04,982 epoch 69 - iter 184/462 - loss 1.36577210\n",
      "2018-11-29 04:22:14,423 epoch 69 - iter 230/462 - loss 1.35509204\n",
      "2018-11-29 04:22:23,984 epoch 69 - iter 276/462 - loss 1.38005465\n",
      "2018-11-29 04:22:33,505 epoch 69 - iter 322/462 - loss 1.37036707\n",
      "2018-11-29 04:22:42,938 epoch 69 - iter 368/462 - loss 1.38046108\n",
      "2018-11-29 04:22:52,262 epoch 69 - iter 414/462 - loss 1.36861909\n",
      "2018-11-29 04:23:02,600 epoch 69 - iter 460/462 - loss 1.36758352\n",
      "2018-11-29 04:23:02,696 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:24:20,452 EPOCH 69: lr 0.1000 - bad epochs 1\n",
      "2018-11-29 04:24:20,453 DEV : f-score 0.9422 - acc 0.9422 - tp 22017 - fp 1092 - fn 1610 - tn 22017\n",
      "2018-11-29 04:24:20,454 TEST: f-score 0.9422 - acc 0.9422 - tp 22017 - fp 1092 - fn 1610 - tn 22017\n",
      "2018-11-29 04:24:20,456 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:24:20,694 epoch 70 - iter 0/462 - loss 1.13565576\n",
      "2018-11-29 04:24:31,774 epoch 70 - iter 46/462 - loss 1.44613901\n",
      "2018-11-29 04:24:41,108 epoch 70 - iter 92/462 - loss 1.39938445\n",
      "2018-11-29 04:24:50,500 epoch 70 - iter 138/462 - loss 1.34190061\n",
      "2018-11-29 04:25:00,034 epoch 70 - iter 184/462 - loss 1.36582834\n",
      "2018-11-29 04:25:09,696 epoch 70 - iter 230/462 - loss 1.35615437\n",
      "2018-11-29 04:25:20,825 epoch 70 - iter 276/462 - loss 1.36461382\n",
      "2018-11-29 04:25:31,605 epoch 70 - iter 322/462 - loss 1.37145660\n",
      "2018-11-29 04:25:42,025 epoch 70 - iter 368/462 - loss 1.36289844\n",
      "2018-11-29 04:25:52,618 epoch 70 - iter 414/462 - loss 1.35795303\n",
      "2018-11-29 04:26:02,365 epoch 70 - iter 460/462 - loss 1.35480010\n",
      "2018-11-29 04:26:02,520 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:27:20,028 EPOCH 70: lr 0.1000 - bad epochs 2\n",
      "2018-11-29 04:27:20,029 DEV : f-score 0.9423 - acc 0.9422 - tp 21951 - fp 1015 - fn 1676 - tn 21951\n",
      "2018-11-29 04:27:20,030 TEST: f-score 0.9423 - acc 0.9422 - tp 21951 - fp 1015 - fn 1676 - tn 21951\n",
      "2018-11-29 04:27:20,030 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:27:20,270 epoch 71 - iter 0/462 - loss 0.88832712\n",
      "2018-11-29 04:27:31,186 epoch 71 - iter 46/462 - loss 1.28632391\n",
      "2018-11-29 04:27:40,588 epoch 71 - iter 92/462 - loss 1.31404071\n",
      "2018-11-29 04:27:49,990 epoch 71 - iter 138/462 - loss 1.33046459\n",
      "2018-11-29 04:28:00,758 epoch 71 - iter 184/462 - loss 1.34695522\n",
      "2018-11-29 04:28:11,344 epoch 71 - iter 230/462 - loss 1.35353793\n",
      "2018-11-29 04:28:22,249 epoch 71 - iter 276/462 - loss 1.37828024\n",
      "2018-11-29 04:28:33,154 epoch 71 - iter 322/462 - loss 1.37065392\n",
      "2018-11-29 04:28:42,421 epoch 71 - iter 368/462 - loss 1.37736708\n",
      "2018-11-29 04:28:51,719 epoch 71 - iter 414/462 - loss 1.36161138\n",
      "2018-11-29 04:29:01,049 epoch 71 - iter 460/462 - loss 1.36199596\n",
      "2018-11-29 04:29:01,150 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:30:18,825 EPOCH 71: lr 0.1000 - bad epochs 3\n",
      "2018-11-29 04:30:18,826 DEV : f-score 0.9390 - acc 0.9390 - tp 21748 - fp 946 - fn 1879 - tn 21748\n",
      "2018-11-29 04:30:18,827 TEST: f-score 0.9390 - acc 0.9390 - tp 21748 - fp 946 - fn 1879 - tn 21748\n",
      "2018-11-29 04:30:18,828 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:30:19,062 epoch 72 - iter 0/462 - loss 1.90968895\n",
      "2018-11-29 04:30:28,180 epoch 72 - iter 46/462 - loss 1.31103224\n",
      "2018-11-29 04:30:37,487 epoch 72 - iter 92/462 - loss 1.35837056\n",
      "2018-11-29 04:30:46,953 epoch 72 - iter 138/462 - loss 1.35018330\n",
      "2018-11-29 04:30:56,117 epoch 72 - iter 184/462 - loss 1.34567119\n",
      "2018-11-29 04:31:05,504 epoch 72 - iter 230/462 - loss 1.33855947\n",
      "2018-11-29 04:31:15,101 epoch 72 - iter 276/462 - loss 1.36875904\n",
      "2018-11-29 04:31:24,334 epoch 72 - iter 322/462 - loss 1.36687557\n",
      "2018-11-29 04:31:34,055 epoch 72 - iter 368/462 - loss 1.36317642\n",
      "2018-11-29 04:31:43,431 epoch 72 - iter 414/462 - loss 1.38658170\n",
      "2018-11-29 04:31:53,088 epoch 72 - iter 460/462 - loss 1.37674708\n",
      "2018-11-29 04:31:53,229 ----------------------------------------------------------------------------------------------------\n",
      "Epoch    71: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2018-11-29 04:33:11,213 EPOCH 72: lr 0.1000 - bad epochs 4\n",
      "2018-11-29 04:33:11,213 DEV : f-score 0.9415 - acc 0.9415 - tp 21946 - fp 1048 - fn 1681 - tn 21946\n",
      "2018-11-29 04:33:11,214 TEST: f-score 0.9415 - acc 0.9415 - tp 21946 - fp 1048 - fn 1681 - tn 21946\n",
      "2018-11-29 04:33:11,215 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:33:11,486 epoch 73 - iter 0/462 - loss 1.41294086\n",
      "2018-11-29 04:33:22,175 epoch 73 - iter 46/462 - loss 1.29911271\n",
      "2018-11-29 04:33:32,928 epoch 73 - iter 92/462 - loss 1.31860439\n",
      "2018-11-29 04:33:43,582 epoch 73 - iter 138/462 - loss 1.28713046\n",
      "2018-11-29 04:33:53,967 epoch 73 - iter 184/462 - loss 1.31424814\n",
      "2018-11-29 04:34:03,448 epoch 73 - iter 230/462 - loss 1.33459686\n",
      "2018-11-29 04:34:12,855 epoch 73 - iter 276/462 - loss 1.32886424\n",
      "2018-11-29 04:34:22,106 epoch 73 - iter 322/462 - loss 1.32390365\n",
      "2018-11-29 04:34:31,555 epoch 73 - iter 368/462 - loss 1.32525461\n",
      "2018-11-29 04:34:40,962 epoch 73 - iter 414/462 - loss 1.32452311\n",
      "2018-11-29 04:34:50,330 epoch 73 - iter 460/462 - loss 1.31098875\n",
      "2018-11-29 04:34:50,438 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:36:08,103 EPOCH 73: lr 0.0500 - bad epochs 0\n",
      "2018-11-29 04:36:08,104 DEV : f-score 0.9432 - acc 0.9432 - tp 21945 - fp 961 - fn 1682 - tn 21945\n",
      "2018-11-29 04:36:08,105 TEST: f-score 0.9432 - acc 0.9432 - tp 21945 - fp 961 - fn 1682 - tn 21945\n",
      "2018-11-29 04:36:08,106 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:36:08,326 epoch 74 - iter 0/462 - loss 0.90263593\n",
      "2018-11-29 04:36:18,748 epoch 74 - iter 46/462 - loss 1.30265478\n",
      "2018-11-29 04:36:29,475 epoch 74 - iter 92/462 - loss 1.25000913\n",
      "2018-11-29 04:36:40,713 epoch 74 - iter 138/462 - loss 1.20769395\n",
      "2018-11-29 04:36:51,676 epoch 74 - iter 184/462 - loss 1.26415133\n",
      "2018-11-29 04:37:01,980 epoch 74 - iter 230/462 - loss 1.27955798\n",
      "2018-11-29 04:37:11,434 epoch 74 - iter 276/462 - loss 1.27879439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-29 04:37:20,894 epoch 74 - iter 322/462 - loss 1.28054260\n",
      "2018-11-29 04:37:30,198 epoch 74 - iter 368/462 - loss 1.28022343\n",
      "2018-11-29 04:37:39,583 epoch 74 - iter 414/462 - loss 1.27641652\n",
      "2018-11-29 04:37:48,687 epoch 74 - iter 460/462 - loss 1.27451729\n",
      "2018-11-29 04:37:48,842 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:39:06,306 EPOCH 74: lr 0.0500 - bad epochs 0\n",
      "2018-11-29 04:39:06,307 DEV : f-score 0.9454 - acc 0.9454 - tp 22061 - fp 984 - fn 1566 - tn 22061\n",
      "2018-11-29 04:39:06,308 TEST: f-score 0.9454 - acc 0.9454 - tp 22061 - fp 984 - fn 1566 - tn 22061\n",
      "2018-11-29 04:39:06,309 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:39:06,557 epoch 75 - iter 0/462 - loss 0.86046386\n",
      "2018-11-29 04:39:16,309 epoch 75 - iter 46/462 - loss 1.32381204\n",
      "2018-11-29 04:39:25,653 epoch 75 - iter 92/462 - loss 1.26944749\n",
      "2018-11-29 04:39:34,604 epoch 75 - iter 138/462 - loss 1.22855082\n",
      "2018-11-29 04:39:44,054 epoch 75 - iter 184/462 - loss 1.23292152\n",
      "2018-11-29 04:39:53,736 epoch 75 - iter 230/462 - loss 1.24059194\n",
      "2018-11-29 04:40:03,359 epoch 75 - iter 276/462 - loss 1.25864263\n",
      "2018-11-29 04:40:12,915 epoch 75 - iter 322/462 - loss 1.25508663\n",
      "2018-11-29 04:40:22,360 epoch 75 - iter 368/462 - loss 1.26238527\n",
      "2018-11-29 04:40:31,667 epoch 75 - iter 414/462 - loss 1.25624468\n",
      "2018-11-29 04:40:40,914 epoch 75 - iter 460/462 - loss 1.25326119\n",
      "2018-11-29 04:40:41,017 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:41:58,552 EPOCH 75: lr 0.0500 - bad epochs 0\n",
      "2018-11-29 04:41:58,553 DEV : f-score 0.9466 - acc 0.9467 - tp 22085 - fp 947 - fn 1542 - tn 22085\n",
      "2018-11-29 04:41:58,554 TEST: f-score 0.9466 - acc 0.9467 - tp 22085 - fp 947 - fn 1542 - tn 22085\n",
      "2018-11-29 04:41:58,555 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:41:58,796 epoch 76 - iter 0/462 - loss 1.69641674\n",
      "2018-11-29 04:42:08,434 epoch 76 - iter 46/462 - loss 1.18561358\n",
      "2018-11-29 04:42:19,484 epoch 76 - iter 92/462 - loss 1.23197977\n",
      "2018-11-29 04:42:29,869 epoch 76 - iter 138/462 - loss 1.20870229\n",
      "2018-11-29 04:42:40,529 epoch 76 - iter 184/462 - loss 1.24433280\n",
      "2018-11-29 04:42:49,599 epoch 76 - iter 230/462 - loss 1.25578700\n",
      "2018-11-29 04:42:58,962 epoch 76 - iter 276/462 - loss 1.27938253\n",
      "2018-11-29 04:43:08,454 epoch 76 - iter 322/462 - loss 1.27090666\n",
      "2018-11-29 04:43:17,585 epoch 76 - iter 368/462 - loss 1.27351262\n",
      "2018-11-29 04:43:27,008 epoch 76 - iter 414/462 - loss 1.26567031\n",
      "2018-11-29 04:43:36,376 epoch 76 - iter 460/462 - loss 1.26488609\n",
      "2018-11-29 04:43:36,487 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:44:54,338 EPOCH 76: lr 0.0500 - bad epochs 0\n",
      "2018-11-29 04:44:54,339 DEV : f-score 0.9473 - acc 0.9473 - tp 22128 - fp 965 - fn 1499 - tn 22128\n",
      "2018-11-29 04:44:54,340 TEST: f-score 0.9473 - acc 0.9473 - tp 22128 - fp 965 - fn 1499 - tn 22128\n",
      "2018-11-29 04:44:54,341 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:44:54,599 epoch 77 - iter 0/462 - loss 2.60703611\n",
      "2018-11-29 04:45:04,153 epoch 77 - iter 46/462 - loss 1.28581405\n",
      "2018-11-29 04:45:13,266 epoch 77 - iter 92/462 - loss 1.31027815\n",
      "2018-11-29 04:45:22,901 epoch 77 - iter 138/462 - loss 1.34350087\n",
      "2018-11-29 04:45:32,688 epoch 77 - iter 184/462 - loss 1.29997510\n",
      "2018-11-29 04:45:42,379 epoch 77 - iter 230/462 - loss 1.30232496\n",
      "2018-11-29 04:45:51,564 epoch 77 - iter 276/462 - loss 1.28234939\n",
      "2018-11-29 04:46:00,948 epoch 77 - iter 322/462 - loss 1.27127044\n",
      "2018-11-29 04:46:10,185 epoch 77 - iter 368/462 - loss 1.26951282\n",
      "2018-11-29 04:46:19,647 epoch 77 - iter 414/462 - loss 1.26370889\n",
      "2018-11-29 04:46:28,993 epoch 77 - iter 460/462 - loss 1.25997457\n",
      "2018-11-29 04:46:29,110 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:47:46,538 EPOCH 77: lr 0.0500 - bad epochs 0\n",
      "2018-11-29 04:47:46,539 DEV : f-score 0.9480 - acc 0.9480 - tp 22181 - fp 986 - fn 1446 - tn 22181\n",
      "2018-11-29 04:47:46,539 TEST: f-score 0.9480 - acc 0.9480 - tp 22181 - fp 986 - fn 1446 - tn 22181\n",
      "2018-11-29 04:47:46,542 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:47:46,768 epoch 78 - iter 0/462 - loss 1.35538995\n",
      "2018-11-29 04:47:56,388 epoch 78 - iter 46/462 - loss 1.22643596\n",
      "2018-11-29 04:48:05,660 epoch 78 - iter 92/462 - loss 1.24983029\n",
      "2018-11-29 04:48:15,284 epoch 78 - iter 138/462 - loss 1.23278867\n",
      "2018-11-29 04:48:24,394 epoch 78 - iter 184/462 - loss 1.24948834\n",
      "2018-11-29 04:48:33,963 epoch 78 - iter 230/462 - loss 1.25856318\n",
      "2018-11-29 04:48:43,274 epoch 78 - iter 276/462 - loss 1.24700993\n",
      "2018-11-29 04:48:52,535 epoch 78 - iter 322/462 - loss 1.27274987\n",
      "2018-11-29 04:49:02,287 epoch 78 - iter 368/462 - loss 1.26212385\n",
      "2018-11-29 04:49:11,470 epoch 78 - iter 414/462 - loss 1.28278344\n",
      "2018-11-29 04:49:20,962 epoch 78 - iter 460/462 - loss 1.26574986\n",
      "2018-11-29 04:49:21,067 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:50:38,991 EPOCH 78: lr 0.0500 - bad epochs 0\n",
      "2018-11-29 04:50:38,992 DEV : f-score 0.9481 - acc 0.9481 - tp 22130 - fp 926 - fn 1497 - tn 22130\n",
      "2018-11-29 04:50:38,993 TEST: f-score 0.9481 - acc 0.9481 - tp 22130 - fp 926 - fn 1497 - tn 22130\n",
      "2018-11-29 04:50:39,004 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:50:39,206 epoch 79 - iter 0/462 - loss 0.97710079\n",
      "2018-11-29 04:50:48,829 epoch 79 - iter 46/462 - loss 1.25566165\n",
      "2018-11-29 04:50:58,457 epoch 79 - iter 92/462 - loss 1.25132513\n",
      "2018-11-29 04:51:07,866 epoch 79 - iter 138/462 - loss 1.22700178\n",
      "2018-11-29 04:51:17,296 epoch 79 - iter 184/462 - loss 1.23279360\n",
      "2018-11-29 04:51:27,076 epoch 79 - iter 230/462 - loss 1.23940694\n",
      "2018-11-29 04:51:36,019 epoch 79 - iter 276/462 - loss 1.20419192\n",
      "2018-11-29 04:51:45,184 epoch 79 - iter 322/462 - loss 1.19319922\n",
      "2018-11-29 04:51:54,772 epoch 79 - iter 368/462 - loss 1.19730727\n",
      "2018-11-29 04:52:04,557 epoch 79 - iter 414/462 - loss 1.20661663\n",
      "2018-11-29 04:52:13,973 epoch 79 - iter 460/462 - loss 1.21070402\n",
      "2018-11-29 04:52:14,090 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:53:31,938 EPOCH 79: lr 0.0500 - bad epochs 0\n",
      "2018-11-29 04:53:31,938 DEV : f-score 0.9492 - acc 0.9492 - tp 22202 - fp 952 - fn 1425 - tn 22202\n",
      "2018-11-29 04:53:31,939 TEST: f-score 0.9492 - acc 0.9492 - tp 22202 - fp 952 - fn 1425 - tn 22202\n",
      "2018-11-29 04:53:31,940 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:53:32,116 epoch 80 - iter 0/462 - loss 1.25425220\n",
      "2018-11-29 04:53:41,625 epoch 80 - iter 46/462 - loss 1.20672055\n",
      "2018-11-29 04:53:50,867 epoch 80 - iter 92/462 - loss 1.16424068\n",
      "2018-11-29 04:54:00,285 epoch 80 - iter 138/462 - loss 1.15509157\n",
      "2018-11-29 04:54:09,444 epoch 80 - iter 184/462 - loss 1.16613467\n",
      "2018-11-29 04:54:18,648 epoch 80 - iter 230/462 - loss 1.18101908\n",
      "2018-11-29 04:54:28,248 epoch 80 - iter 276/462 - loss 1.18506238\n",
      "2018-11-29 04:54:37,781 epoch 80 - iter 322/462 - loss 1.20517365\n",
      "2018-11-29 04:54:47,146 epoch 80 - iter 368/462 - loss 1.20869506\n",
      "2018-11-29 04:54:56,377 epoch 80 - iter 414/462 - loss 1.21250740\n",
      "2018-11-29 04:55:06,326 epoch 80 - iter 460/462 - loss 1.22690304\n",
      "2018-11-29 04:55:06,426 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:56:25,713 EPOCH 80: lr 0.0500 - bad epochs 0\n",
      "2018-11-29 04:56:25,714 DEV : f-score 0.9498 - acc 0.9498 - tp 22215 - fp 936 - fn 1412 - tn 22215\n",
      "2018-11-29 04:56:25,714 TEST: f-score 0.9498 - acc 0.9498 - tp 22215 - fp 936 - fn 1412 - tn 22215\n",
      "2018-11-29 04:56:25,715 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:56:25,922 epoch 81 - iter 0/462 - loss 0.47640502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-29 04:56:35,623 epoch 81 - iter 46/462 - loss 1.28110327\n",
      "2018-11-29 04:56:44,991 epoch 81 - iter 92/462 - loss 1.21895466\n",
      "2018-11-29 04:56:54,579 epoch 81 - iter 138/462 - loss 1.16673914\n",
      "2018-11-29 04:57:04,266 epoch 81 - iter 184/462 - loss 1.18738899\n",
      "2018-11-29 04:57:13,661 epoch 81 - iter 230/462 - loss 1.19983054\n",
      "2018-11-29 04:57:23,145 epoch 81 - iter 276/462 - loss 1.22247770\n",
      "2018-11-29 04:57:32,250 epoch 81 - iter 322/462 - loss 1.22041062\n",
      "2018-11-29 04:57:41,611 epoch 81 - iter 368/462 - loss 1.22238994\n",
      "2018-11-29 04:57:51,208 epoch 81 - iter 414/462 - loss 1.22901260\n",
      "2018-11-29 04:58:00,936 epoch 81 - iter 460/462 - loss 1.22895486\n",
      "2018-11-29 04:58:01,051 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:59:18,442 EPOCH 81: lr 0.0500 - bad epochs 0\n",
      "2018-11-29 04:59:18,443 DEV : f-score 0.9504 - acc 0.9504 - tp 22210 - fp 902 - fn 1417 - tn 22210\n",
      "2018-11-29 04:59:18,443 TEST: f-score 0.9504 - acc 0.9504 - tp 22210 - fp 902 - fn 1417 - tn 22210\n",
      "2018-11-29 04:59:18,444 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 04:59:18,639 epoch 82 - iter 0/462 - loss 0.93339485\n",
      "2018-11-29 04:59:28,899 epoch 82 - iter 46/462 - loss 1.26477077\n",
      "2018-11-29 04:59:38,561 epoch 82 - iter 92/462 - loss 1.29539776\n",
      "2018-11-29 04:59:47,862 epoch 82 - iter 138/462 - loss 1.23193636\n",
      "2018-11-29 04:59:56,858 epoch 82 - iter 184/462 - loss 1.21453658\n",
      "2018-11-29 05:00:06,559 epoch 82 - iter 230/462 - loss 1.19466714\n",
      "2018-11-29 05:00:16,064 epoch 82 - iter 276/462 - loss 1.20836050\n",
      "2018-11-29 05:00:25,280 epoch 82 - iter 322/462 - loss 1.19162133\n",
      "2018-11-29 05:00:34,881 epoch 82 - iter 368/462 - loss 1.18215401\n",
      "2018-11-29 05:00:44,589 epoch 82 - iter 414/462 - loss 1.19297534\n",
      "2018-11-29 05:00:53,823 epoch 82 - iter 460/462 - loss 1.19160847\n",
      "2018-11-29 05:00:53,940 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:02:11,483 EPOCH 82: lr 0.0500 - bad epochs 0\n",
      "2018-11-29 05:02:11,484 DEV : f-score 0.9509 - acc 0.9509 - tp 22267 - fp 939 - fn 1360 - tn 22267\n",
      "2018-11-29 05:02:11,484 TEST: f-score 0.9509 - acc 0.9509 - tp 22267 - fp 939 - fn 1360 - tn 22267\n",
      "2018-11-29 05:02:11,485 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:02:11,761 epoch 83 - iter 0/462 - loss 1.36831367\n",
      "2018-11-29 05:02:20,955 epoch 83 - iter 46/462 - loss 1.15277526\n",
      "2018-11-29 05:02:30,580 epoch 83 - iter 92/462 - loss 1.24176499\n",
      "2018-11-29 05:02:40,052 epoch 83 - iter 138/462 - loss 1.20014312\n",
      "2018-11-29 05:02:49,168 epoch 83 - iter 184/462 - loss 1.21919826\n",
      "2018-11-29 05:02:58,487 epoch 83 - iter 230/462 - loss 1.20951818\n",
      "2018-11-29 05:03:07,782 epoch 83 - iter 276/462 - loss 1.20398729\n",
      "2018-11-29 05:03:17,133 epoch 83 - iter 322/462 - loss 1.20581852\n",
      "2018-11-29 05:03:26,619 epoch 83 - iter 368/462 - loss 1.20516960\n",
      "2018-11-29 05:03:37,190 epoch 83 - iter 414/462 - loss 1.20641827\n",
      "2018-11-29 05:03:48,092 epoch 83 - iter 460/462 - loss 1.19822101\n",
      "2018-11-29 05:03:48,200 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:05:05,463 EPOCH 83: lr 0.0500 - bad epochs 0\n",
      "2018-11-29 05:05:05,464 DEV : f-score 0.9502 - acc 0.9502 - tp 22257 - fp 963 - fn 1370 - tn 22257\n",
      "2018-11-29 05:05:05,465 TEST: f-score 0.9502 - acc 0.9502 - tp 22257 - fp 963 - fn 1370 - tn 22257\n",
      "2018-11-29 05:05:05,466 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:05:05,637 epoch 84 - iter 0/462 - loss 0.77102232\n",
      "2018-11-29 05:05:16,910 epoch 84 - iter 46/462 - loss 1.17602236\n",
      "2018-11-29 05:05:27,630 epoch 84 - iter 92/462 - loss 1.15453006\n",
      "2018-11-29 05:05:37,882 epoch 84 - iter 138/462 - loss 1.19094998\n",
      "2018-11-29 05:05:48,740 epoch 84 - iter 184/462 - loss 1.22236330\n",
      "2018-11-29 05:05:58,176 epoch 84 - iter 230/462 - loss 1.21231782\n",
      "2018-11-29 05:06:07,539 epoch 84 - iter 276/462 - loss 1.21914888\n",
      "2018-11-29 05:06:16,968 epoch 84 - iter 322/462 - loss 1.22338041\n",
      "2018-11-29 05:06:26,168 epoch 84 - iter 368/462 - loss 1.22268546\n",
      "2018-11-29 05:06:35,692 epoch 84 - iter 414/462 - loss 1.21807700\n",
      "2018-11-29 05:06:45,013 epoch 84 - iter 460/462 - loss 1.22558485\n",
      "2018-11-29 05:06:45,095 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:08:02,728 EPOCH 84: lr 0.0500 - bad epochs 1\n",
      "2018-11-29 05:08:02,729 DEV : f-score 0.9510 - acc 0.9510 - tp 22241 - fp 906 - fn 1386 - tn 22241\n",
      "2018-11-29 05:08:02,730 TEST: f-score 0.9510 - acc 0.9510 - tp 22241 - fp 906 - fn 1386 - tn 22241\n",
      "2018-11-29 05:08:02,737 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:08:02,927 epoch 85 - iter 0/462 - loss 1.24954653\n",
      "2018-11-29 05:08:12,501 epoch 85 - iter 46/462 - loss 1.13947575\n",
      "2018-11-29 05:08:21,706 epoch 85 - iter 92/462 - loss 1.15829249\n",
      "2018-11-29 05:08:31,081 epoch 85 - iter 138/462 - loss 1.15222152\n",
      "2018-11-29 05:08:40,444 epoch 85 - iter 184/462 - loss 1.19619311\n",
      "2018-11-29 05:08:49,550 epoch 85 - iter 230/462 - loss 1.18593773\n",
      "2018-11-29 05:08:58,955 epoch 85 - iter 276/462 - loss 1.18808259\n",
      "2018-11-29 05:09:08,572 epoch 85 - iter 322/462 - loss 1.18793445\n",
      "2018-11-29 05:09:17,746 epoch 85 - iter 368/462 - loss 1.18291342\n",
      "2018-11-29 05:09:27,076 epoch 85 - iter 414/462 - loss 1.18262028\n",
      "2018-11-29 05:09:36,808 epoch 85 - iter 460/462 - loss 1.18340620\n",
      "2018-11-29 05:09:36,955 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:10:55,169 EPOCH 85: lr 0.0500 - bad epochs 0\n",
      "2018-11-29 05:10:55,170 DEV : f-score 0.9509 - acc 0.9510 - tp 22219 - fp 884 - fn 1408 - tn 22219\n",
      "2018-11-29 05:10:55,170 TEST: f-score 0.9509 - acc 0.9510 - tp 22219 - fp 884 - fn 1408 - tn 22219\n",
      "2018-11-29 05:10:55,171 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:10:55,384 epoch 86 - iter 0/462 - loss 1.36202741\n",
      "2018-11-29 05:11:05,790 epoch 86 - iter 46/462 - loss 1.29571789\n",
      "2018-11-29 05:11:16,162 epoch 86 - iter 92/462 - loss 1.20933031\n",
      "2018-11-29 05:11:27,292 epoch 86 - iter 138/462 - loss 1.18421248\n",
      "2018-11-29 05:11:37,743 epoch 86 - iter 184/462 - loss 1.16016971\n",
      "2018-11-29 05:11:48,485 epoch 86 - iter 230/462 - loss 1.17680405\n",
      "2018-11-29 05:11:58,283 epoch 86 - iter 276/462 - loss 1.18594358\n",
      "2018-11-29 05:12:08,617 epoch 86 - iter 322/462 - loss 1.18026366\n",
      "2018-11-29 05:12:18,387 epoch 86 - iter 368/462 - loss 1.18961884\n",
      "2018-11-29 05:12:27,712 epoch 86 - iter 414/462 - loss 1.20652065\n",
      "2018-11-29 05:12:36,966 epoch 86 - iter 460/462 - loss 1.20301431\n",
      "2018-11-29 05:12:37,076 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:13:55,316 EPOCH 86: lr 0.0500 - bad epochs 1\n",
      "2018-11-29 05:13:55,317 DEV : f-score 0.9523 - acc 0.9522 - tp 22291 - fp 901 - fn 1336 - tn 22291\n",
      "2018-11-29 05:13:55,318 TEST: f-score 0.9523 - acc 0.9522 - tp 22291 - fp 901 - fn 1336 - tn 22291\n",
      "2018-11-29 05:13:55,320 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:13:55,548 epoch 87 - iter 0/462 - loss 0.74046803\n",
      "2018-11-29 05:14:06,063 epoch 87 - iter 46/462 - loss 1.20344727\n",
      "2018-11-29 05:14:15,346 epoch 87 - iter 92/462 - loss 1.18292033\n",
      "2018-11-29 05:14:24,549 epoch 87 - iter 138/462 - loss 1.19857043\n",
      "2018-11-29 05:14:33,911 epoch 87 - iter 184/462 - loss 1.18293786\n",
      "2018-11-29 05:14:43,617 epoch 87 - iter 230/462 - loss 1.19988252\n",
      "2018-11-29 05:14:54,287 epoch 87 - iter 276/462 - loss 1.19807083\n",
      "2018-11-29 05:15:05,140 epoch 87 - iter 322/462 - loss 1.19454581\n",
      "2018-11-29 05:15:15,422 epoch 87 - iter 368/462 - loss 1.19760613\n",
      "2018-11-29 05:15:24,983 epoch 87 - iter 414/462 - loss 1.20669702\n",
      "2018-11-29 05:15:34,466 epoch 87 - iter 460/462 - loss 1.21616444\n",
      "2018-11-29 05:15:34,550 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:16:52,041 EPOCH 87: lr 0.0500 - bad epochs 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-29 05:16:52,042 DEV : f-score 0.9514 - acc 0.9514 - tp 22236 - fp 880 - fn 1391 - tn 22236\n",
      "2018-11-29 05:16:52,043 TEST: f-score 0.9514 - acc 0.9514 - tp 22236 - fp 880 - fn 1391 - tn 22236\n",
      "2018-11-29 05:16:52,044 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:16:52,257 epoch 88 - iter 0/462 - loss 1.43969154\n",
      "2018-11-29 05:17:03,201 epoch 88 - iter 46/462 - loss 1.29068403\n",
      "2018-11-29 05:17:13,507 epoch 88 - iter 92/462 - loss 1.18027021\n",
      "2018-11-29 05:17:23,881 epoch 88 - iter 138/462 - loss 1.15806419\n",
      "2018-11-29 05:17:33,349 epoch 88 - iter 184/462 - loss 1.14222054\n",
      "2018-11-29 05:17:42,730 epoch 88 - iter 230/462 - loss 1.17642743\n",
      "2018-11-29 05:17:52,717 epoch 88 - iter 276/462 - loss 1.17660003\n",
      "2018-11-29 05:18:03,559 epoch 88 - iter 322/462 - loss 1.18822776\n",
      "2018-11-29 05:18:14,714 epoch 88 - iter 368/462 - loss 1.18054102\n",
      "2018-11-29 05:18:25,758 epoch 88 - iter 414/462 - loss 1.18000932\n",
      "2018-11-29 05:18:36,716 epoch 88 - iter 460/462 - loss 1.17651987\n",
      "2018-11-29 05:18:36,847 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:19:54,297 EPOCH 88: lr 0.0500 - bad epochs 1\n",
      "2018-11-29 05:19:54,298 DEV : f-score 0.9520 - acc 0.9520 - tp 22237 - fp 852 - fn 1390 - tn 22237\n",
      "2018-11-29 05:19:54,299 TEST: f-score 0.9520 - acc 0.9520 - tp 22237 - fp 852 - fn 1390 - tn 22237\n",
      "2018-11-29 05:19:54,300 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:19:54,534 epoch 89 - iter 0/462 - loss 1.04674172\n",
      "2018-11-29 05:20:05,112 epoch 89 - iter 46/462 - loss 1.12691136\n",
      "2018-11-29 05:20:16,332 epoch 89 - iter 92/462 - loss 1.14794431\n",
      "2018-11-29 05:20:27,764 epoch 89 - iter 138/462 - loss 1.15851977\n",
      "2018-11-29 05:20:38,738 epoch 89 - iter 184/462 - loss 1.19775934\n",
      "2018-11-29 05:20:48,047 epoch 89 - iter 230/462 - loss 1.19862176\n",
      "2018-11-29 05:20:57,365 epoch 89 - iter 276/462 - loss 1.18850587\n",
      "2018-11-29 05:21:08,155 epoch 89 - iter 322/462 - loss 1.17986797\n",
      "2018-11-29 05:21:18,841 epoch 89 - iter 368/462 - loss 1.18225704\n",
      "2018-11-29 05:21:29,483 epoch 89 - iter 414/462 - loss 1.18246325\n",
      "2018-11-29 05:21:40,551 epoch 89 - iter 460/462 - loss 1.17015408\n",
      "2018-11-29 05:21:40,668 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:22:58,783 EPOCH 89: lr 0.0500 - bad epochs 2\n",
      "2018-11-29 05:22:58,784 DEV : f-score 0.9520 - acc 0.9520 - tp 22247 - fp 862 - fn 1380 - tn 22247\n",
      "2018-11-29 05:22:58,785 TEST: f-score 0.9520 - acc 0.9520 - tp 22247 - fp 862 - fn 1380 - tn 22247\n",
      "2018-11-29 05:22:58,786 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:22:59,091 epoch 90 - iter 0/462 - loss 0.84059238\n",
      "2018-11-29 05:23:09,472 epoch 90 - iter 46/462 - loss 1.18213428\n",
      "2018-11-29 05:23:19,058 epoch 90 - iter 92/462 - loss 1.15604144\n",
      "2018-11-29 05:23:28,396 epoch 90 - iter 138/462 - loss 1.14592584\n",
      "2018-11-29 05:23:38,007 epoch 90 - iter 184/462 - loss 1.16367384\n",
      "2018-11-29 05:23:47,239 epoch 90 - iter 230/462 - loss 1.14788542\n",
      "2018-11-29 05:23:56,680 epoch 90 - iter 276/462 - loss 1.14482211\n",
      "2018-11-29 05:24:06,193 epoch 90 - iter 322/462 - loss 1.16042136\n",
      "2018-11-29 05:24:15,504 epoch 90 - iter 368/462 - loss 1.16072240\n",
      "2018-11-29 05:24:24,747 epoch 90 - iter 414/462 - loss 1.16675199\n",
      "2018-11-29 05:24:34,177 epoch 90 - iter 460/462 - loss 1.17763078\n",
      "2018-11-29 05:24:34,333 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:25:51,869 EPOCH 90: lr 0.0500 - bad epochs 3\n",
      "2018-11-29 05:25:51,869 DEV : f-score 0.9521 - acc 0.9521 - tp 22238 - fp 849 - fn 1389 - tn 22238\n",
      "2018-11-29 05:25:51,870 TEST: f-score 0.9521 - acc 0.9521 - tp 22238 - fp 849 - fn 1389 - tn 22238\n",
      "2018-11-29 05:25:51,871 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:25:52,115 epoch 91 - iter 0/462 - loss 0.77861691\n",
      "2018-11-29 05:26:01,681 epoch 91 - iter 46/462 - loss 1.24408359\n",
      "2018-11-29 05:26:11,033 epoch 91 - iter 92/462 - loss 1.24415405\n",
      "2018-11-29 05:26:20,721 epoch 91 - iter 138/462 - loss 1.23228779\n",
      "2018-11-29 05:26:29,552 epoch 91 - iter 184/462 - loss 1.19259657\n",
      "2018-11-29 05:26:39,258 epoch 91 - iter 230/462 - loss 1.20856842\n",
      "2018-11-29 05:26:48,444 epoch 91 - iter 276/462 - loss 1.21220434\n",
      "2018-11-29 05:26:57,957 epoch 91 - iter 322/462 - loss 1.20557397\n",
      "2018-11-29 05:27:07,404 epoch 91 - iter 368/462 - loss 1.19653851\n",
      "2018-11-29 05:27:16,666 epoch 91 - iter 414/462 - loss 1.19355138\n",
      "2018-11-29 05:27:26,162 epoch 91 - iter 460/462 - loss 1.19453110\n",
      "2018-11-29 05:27:26,290 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:28:44,004 EPOCH 91: lr 0.0500 - bad epochs 4\n",
      "2018-11-29 05:28:44,005 DEV : f-score 0.9531 - acc 0.9531 - tp 22306 - fp 873 - fn 1321 - tn 22306\n",
      "2018-11-29 05:28:44,005 TEST: f-score 0.9531 - acc 0.9531 - tp 22306 - fp 873 - fn 1321 - tn 22306\n",
      "2018-11-29 05:28:44,007 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:28:44,225 epoch 92 - iter 0/462 - loss 1.01383936\n",
      "2018-11-29 05:28:54,789 epoch 92 - iter 46/462 - loss 1.20523551\n",
      "2018-11-29 05:29:05,997 epoch 92 - iter 92/462 - loss 1.18055781\n",
      "2018-11-29 05:29:16,668 epoch 92 - iter 138/462 - loss 1.17115159\n",
      "2018-11-29 05:29:27,419 epoch 92 - iter 184/462 - loss 1.13944482\n",
      "2018-11-29 05:29:38,132 epoch 92 - iter 230/462 - loss 1.16389758\n",
      "2018-11-29 05:29:49,033 epoch 92 - iter 276/462 - loss 1.17689752\n",
      "2018-11-29 05:29:58,616 epoch 92 - iter 322/462 - loss 1.16859593\n",
      "2018-11-29 05:30:07,815 epoch 92 - iter 368/462 - loss 1.15556899\n",
      "2018-11-29 05:30:17,147 epoch 92 - iter 414/462 - loss 1.16377939\n",
      "2018-11-29 05:30:28,182 epoch 92 - iter 460/462 - loss 1.16599465\n",
      "2018-11-29 05:30:28,327 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:31:45,635 EPOCH 92: lr 0.0500 - bad epochs 0\n",
      "2018-11-29 05:31:45,636 DEV : f-score 0.9538 - acc 0.9538 - tp 22321 - fp 858 - fn 1306 - tn 22321\n",
      "2018-11-29 05:31:45,636 TEST: f-score 0.9538 - acc 0.9538 - tp 22321 - fp 858 - fn 1306 - tn 22321\n",
      "2018-11-29 05:31:45,637 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:31:45,900 epoch 93 - iter 0/462 - loss 1.29646873\n",
      "2018-11-29 05:31:56,665 epoch 93 - iter 46/462 - loss 1.10729820\n",
      "2018-11-29 05:32:07,269 epoch 93 - iter 92/462 - loss 1.13765282\n",
      "2018-11-29 05:32:17,796 epoch 93 - iter 138/462 - loss 1.14046842\n",
      "2018-11-29 05:32:28,870 epoch 93 - iter 184/462 - loss 1.16833004\n",
      "2018-11-29 05:32:39,778 epoch 93 - iter 230/462 - loss 1.15025622\n",
      "2018-11-29 05:32:50,556 epoch 93 - iter 276/462 - loss 1.16013666\n",
      "2018-11-29 05:33:01,215 epoch 93 - iter 322/462 - loss 1.14317583\n",
      "2018-11-29 05:33:10,827 epoch 93 - iter 368/462 - loss 1.15760767\n",
      "2018-11-29 05:33:20,362 epoch 93 - iter 414/462 - loss 1.15599221\n",
      "2018-11-29 05:33:30,991 epoch 93 - iter 460/462 - loss 1.16119614\n",
      "2018-11-29 05:33:31,074 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:34:48,582 EPOCH 93: lr 0.0500 - bad epochs 0\n",
      "2018-11-29 05:34:48,583 DEV : f-score 0.9534 - acc 0.9534 - tp 22263 - fp 812 - fn 1364 - tn 22263\n",
      "2018-11-29 05:34:48,583 TEST: f-score 0.9534 - acc 0.9534 - tp 22263 - fp 812 - fn 1364 - tn 22263\n",
      "2018-11-29 05:34:48,587 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:34:48,773 epoch 94 - iter 0/462 - loss 1.45857573\n",
      "2018-11-29 05:34:59,951 epoch 94 - iter 46/462 - loss 1.21579652\n",
      "2018-11-29 05:35:10,309 epoch 94 - iter 92/462 - loss 1.20138259\n",
      "2018-11-29 05:35:21,132 epoch 94 - iter 138/462 - loss 1.18356020\n",
      "2018-11-29 05:35:31,833 epoch 94 - iter 184/462 - loss 1.15477679\n",
      "2018-11-29 05:35:42,954 epoch 94 - iter 230/462 - loss 1.16709307\n",
      "2018-11-29 05:35:54,061 epoch 94 - iter 276/462 - loss 1.16152955\n",
      "2018-11-29 05:36:03,571 epoch 94 - iter 322/462 - loss 1.16475979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-29 05:36:12,599 epoch 94 - iter 368/462 - loss 1.16127880\n",
      "2018-11-29 05:36:21,776 epoch 94 - iter 414/462 - loss 1.16053764\n",
      "2018-11-29 05:36:31,029 epoch 94 - iter 460/462 - loss 1.16312396\n",
      "2018-11-29 05:36:31,136 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:37:48,731 EPOCH 94: lr 0.0500 - bad epochs 1\n",
      "2018-11-29 05:37:48,732 DEV : f-score 0.9537 - acc 0.9537 - tp 22305 - fp 845 - fn 1322 - tn 22305\n",
      "2018-11-29 05:37:48,733 TEST: f-score 0.9537 - acc 0.9537 - tp 22305 - fp 845 - fn 1322 - tn 22305\n",
      "2018-11-29 05:37:48,734 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:37:48,981 epoch 95 - iter 0/462 - loss 1.67304444\n",
      "2018-11-29 05:38:00,178 epoch 95 - iter 46/462 - loss 1.14772475\n",
      "2018-11-29 05:38:10,855 epoch 95 - iter 92/462 - loss 1.16586770\n",
      "2018-11-29 05:38:20,578 epoch 95 - iter 138/462 - loss 1.17999476\n",
      "2018-11-29 05:38:29,950 epoch 95 - iter 184/462 - loss 1.15939802\n",
      "2018-11-29 05:38:39,281 epoch 95 - iter 230/462 - loss 1.15826301\n",
      "2018-11-29 05:38:48,804 epoch 95 - iter 276/462 - loss 1.16544144\n",
      "2018-11-29 05:38:58,131 epoch 95 - iter 322/462 - loss 1.15150099\n",
      "2018-11-29 05:39:07,391 epoch 95 - iter 368/462 - loss 1.15417390\n",
      "2018-11-29 05:39:16,676 epoch 95 - iter 414/462 - loss 1.15190964\n",
      "2018-11-29 05:39:26,315 epoch 95 - iter 460/462 - loss 1.15729000\n",
      "2018-11-29 05:39:26,442 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:40:44,337 EPOCH 95: lr 0.0500 - bad epochs 2\n",
      "2018-11-29 05:40:44,338 DEV : f-score 0.9539 - acc 0.9539 - tp 22310 - fp 840 - fn 1317 - tn 22310\n",
      "2018-11-29 05:40:44,338 TEST: f-score 0.9539 - acc 0.9539 - tp 22310 - fp 840 - fn 1317 - tn 22310\n",
      "2018-11-29 05:40:44,341 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:40:44,592 epoch 96 - iter 0/462 - loss 1.32735121\n",
      "2018-11-29 05:40:55,126 epoch 96 - iter 46/462 - loss 1.13671508\n",
      "2018-11-29 05:41:04,914 epoch 96 - iter 92/462 - loss 1.13742454\n",
      "2018-11-29 05:41:14,270 epoch 96 - iter 138/462 - loss 1.13692960\n",
      "2018-11-29 05:41:24,061 epoch 96 - iter 184/462 - loss 1.15577813\n",
      "2018-11-29 05:41:33,101 epoch 96 - iter 230/462 - loss 1.16198981\n",
      "2018-11-29 05:41:42,435 epoch 96 - iter 276/462 - loss 1.15439469\n",
      "2018-11-29 05:41:51,908 epoch 96 - iter 322/462 - loss 1.14920139\n",
      "2018-11-29 05:42:02,033 epoch 96 - iter 368/462 - loss 1.16489098\n",
      "2018-11-29 05:42:11,354 epoch 96 - iter 414/462 - loss 1.17298586\n",
      "2018-11-29 05:42:20,757 epoch 96 - iter 460/462 - loss 1.17090983\n",
      "2018-11-29 05:42:20,862 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:43:39,196 EPOCH 96: lr 0.0500 - bad epochs 0\n",
      "2018-11-29 05:43:39,197 DEV : f-score 0.9541 - acc 0.9541 - tp 22329 - fp 851 - fn 1298 - tn 22329\n",
      "2018-11-29 05:43:39,197 TEST: f-score 0.9541 - acc 0.9541 - tp 22329 - fp 851 - fn 1298 - tn 22329\n",
      "2018-11-29 05:43:39,200 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:43:39,415 epoch 97 - iter 0/462 - loss 2.04852152\n",
      "2018-11-29 05:43:48,952 epoch 97 - iter 46/462 - loss 1.21037684\n",
      "2018-11-29 05:43:58,293 epoch 97 - iter 92/462 - loss 1.20651904\n",
      "2018-11-29 05:44:07,563 epoch 97 - iter 138/462 - loss 1.19352546\n",
      "2018-11-29 05:44:17,305 epoch 97 - iter 184/462 - loss 1.18316859\n",
      "2018-11-29 05:44:26,552 epoch 97 - iter 230/462 - loss 1.18390732\n",
      "2018-11-29 05:44:35,809 epoch 97 - iter 276/462 - loss 1.16155227\n",
      "2018-11-29 05:44:45,164 epoch 97 - iter 322/462 - loss 1.15062535\n",
      "2018-11-29 05:44:54,608 epoch 97 - iter 368/462 - loss 1.14865572\n",
      "2018-11-29 05:45:04,113 epoch 97 - iter 414/462 - loss 1.15307399\n",
      "2018-11-29 05:45:13,654 epoch 97 - iter 460/462 - loss 1.16224635\n",
      "2018-11-29 05:45:13,771 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:46:31,643 EPOCH 97: lr 0.0500 - bad epochs 0\n",
      "2018-11-29 05:46:31,644 DEV : f-score 0.9546 - acc 0.9546 - tp 22366 - fp 865 - fn 1261 - tn 22366\n",
      "2018-11-29 05:46:31,645 TEST: f-score 0.9546 - acc 0.9546 - tp 22366 - fp 865 - fn 1261 - tn 22366\n",
      "2018-11-29 05:46:31,646 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:46:31,856 epoch 98 - iter 0/462 - loss 2.12396908\n",
      "2018-11-29 05:46:42,528 epoch 98 - iter 46/462 - loss 1.07344945\n",
      "2018-11-29 05:46:52,676 epoch 98 - iter 92/462 - loss 1.10186321\n",
      "2018-11-29 05:47:03,293 epoch 98 - iter 138/462 - loss 1.10071889\n",
      "2018-11-29 05:47:13,796 epoch 98 - iter 184/462 - loss 1.13885144\n",
      "2018-11-29 05:47:24,752 epoch 98 - iter 230/462 - loss 1.14526794\n",
      "2018-11-29 05:47:34,478 epoch 98 - iter 276/462 - loss 1.14621148\n",
      "2018-11-29 05:47:43,800 epoch 98 - iter 322/462 - loss 1.14150511\n",
      "2018-11-29 05:47:53,091 epoch 98 - iter 368/462 - loss 1.15498187\n",
      "2018-11-29 05:48:02,360 epoch 98 - iter 414/462 - loss 1.14969094\n",
      "2018-11-29 05:48:12,653 epoch 98 - iter 460/462 - loss 1.15493570\n",
      "2018-11-29 05:48:12,794 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:49:32,403 EPOCH 98: lr 0.0500 - bad epochs 0\n",
      "2018-11-29 05:49:32,404 DEV : f-score 0.9545 - acc 0.9545 - tp 22413 - fp 924 - fn 1214 - tn 22413\n",
      "2018-11-29 05:49:32,404 TEST: f-score 0.9545 - acc 0.9545 - tp 22413 - fp 924 - fn 1214 - tn 22413\n",
      "2018-11-29 05:49:32,405 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:49:32,657 epoch 99 - iter 0/462 - loss 1.27011168\n",
      "2018-11-29 05:49:43,312 epoch 99 - iter 46/462 - loss 1.14298789\n",
      "2018-11-29 05:49:56,153 epoch 99 - iter 92/462 - loss 1.14045543\n",
      "2018-11-29 05:50:06,610 epoch 99 - iter 138/462 - loss 1.12122452\n",
      "2018-11-29 05:50:18,164 epoch 99 - iter 184/462 - loss 1.14865346\n",
      "2018-11-29 05:50:29,000 epoch 99 - iter 230/462 - loss 1.13895993\n",
      "2018-11-29 05:50:38,356 epoch 99 - iter 276/462 - loss 1.15233181\n",
      "2018-11-29 05:50:47,709 epoch 99 - iter 322/462 - loss 1.14196234\n",
      "2018-11-29 05:50:57,038 epoch 99 - iter 368/462 - loss 1.13765166\n",
      "2018-11-29 05:51:06,649 epoch 99 - iter 414/462 - loss 1.15380201\n",
      "2018-11-29 05:51:16,055 epoch 99 - iter 460/462 - loss 1.14895851\n",
      "2018-11-29 05:51:16,190 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:52:34,465 EPOCH 99: lr 0.0500 - bad epochs 1\n",
      "2018-11-29 05:52:34,466 DEV : f-score 0.9556 - acc 0.9556 - tp 22377 - fp 830 - fn 1250 - tn 22377\n",
      "2018-11-29 05:52:34,467 TEST: f-score 0.9556 - acc 0.9556 - tp 22377 - fp 830 - fn 1250 - tn 22377\n",
      "2018-11-29 05:52:34,469 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:52:34,726 epoch 100 - iter 0/462 - loss 1.75419986\n",
      "2018-11-29 05:52:45,666 epoch 100 - iter 46/462 - loss 1.18449262\n",
      "2018-11-29 05:52:55,071 epoch 100 - iter 92/462 - loss 1.13487197\n",
      "2018-11-29 05:53:04,316 epoch 100 - iter 138/462 - loss 1.18189009\n",
      "2018-11-29 05:53:13,713 epoch 100 - iter 184/462 - loss 1.17078189\n",
      "2018-11-29 05:53:23,110 epoch 100 - iter 230/462 - loss 1.17495912\n",
      "2018-11-29 05:53:32,346 epoch 100 - iter 276/462 - loss 1.18035913\n",
      "2018-11-29 05:53:41,844 epoch 100 - iter 322/462 - loss 1.18046280\n",
      "2018-11-29 05:53:51,252 epoch 100 - iter 368/462 - loss 1.18460334\n",
      "2018-11-29 05:54:00,387 epoch 100 - iter 414/462 - loss 1.17155448\n",
      "2018-11-29 05:54:10,246 epoch 100 - iter 460/462 - loss 1.16521812\n",
      "2018-11-29 05:54:10,389 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:55:29,480 EPOCH 100: lr 0.0500 - bad epochs 0\n",
      "2018-11-29 05:55:29,481 DEV : f-score 0.9540 - acc 0.9540 - tp 22335 - fp 863 - fn 1292 - tn 22335\n",
      "2018-11-29 05:55:29,481 TEST: f-score 0.9540 - acc 0.9540 - tp 22335 - fp 863 - fn 1292 - tn 22335\n",
      "2018-11-29 05:55:29,482 ----------------------------------------------------------------------------------------------------\n",
      "2018-11-29 05:55:29,483 TEST: f-score 0.9540 - acc 0.9540 - tp 22335 - fp 863 - fn 1292 - tn 22335\n",
      "2018-11-29 05:55:29,483 LOC : f-score 0.9719 - acc 0.9719 - tp 6966 - fp 198 - fn 205 - tn 6966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-29 05:55:29,484 MISC: f-score 0.9132 - acc 0.9132 - tp 3067 - fp 172 - fn 411 - tn 3067\n",
      "2018-11-29 05:55:29,485 ORG : f-score 0.9276 - acc 0.9276 - tp 5610 - fp 360 - fn 516 - tn 5610\n",
      "2018-11-29 05:55:29,492 PER : f-score 0.9785 - acc 0.9786 - tp 6692 - fp 133 - fn 160 - tn 6692\n"
     ]
    }
   ],
   "source": [
    "# define columns\n",
    "columns = {0: 'text', 1: 'pos', 2: 'cnk', 3:'ner'}\n",
    "\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = 'Dataset/'\n",
    "\n",
    "# training folder\n",
    "flair_folder = 'Flair/'\n",
    "flair_path = Path(flair_folder)\n",
    "if not flair_path.exists():\n",
    "    flair_path.mkdir()\n",
    "        \n",
    "# retrieve corpus using column format, data folder and the names of the train, dev and test files\n",
    "# 1. get the corpus\n",
    "corpus: TaggedCorpus = NLPTaskDataFetcher.fetch_column_corpus(data_folder, columns,\n",
    "                                                              train_file='ner_dataset_training.txt',\n",
    "                                                              test_file='ner_dataset_test.txt',\n",
    "                                                              dev_file='ner_dataset_validation.txt')\n",
    "                \n",
    "# 2. what tag do we want to predict?\n",
    "tag_type = 'ner'\n",
    "\n",
    "# 3. make the tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "print(tag_dictionary.idx2item)\n",
    "\n",
    "# 4. initialize embeddings\n",
    "embedding_types: List[TokenEmbeddings] = [\n",
    "\n",
    "    # use this if you have a potato PC\n",
    "    WordEmbeddings('glove'),\n",
    "\n",
    "    # comment in this line to use character embeddings\n",
    "    # CharacterEmbeddings(),\n",
    "\n",
    "    # comment in these lines to use contextual string embeddings\n",
    "#     CharLMEmbeddings('news-forward'),\n",
    "#     CharLMEmbeddings('news-backward'),\n",
    "]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "    \n",
    "\n",
    "# 5. initialize sequence tagger\n",
    "tagger: SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                        embeddings=embeddings,\n",
    "                                        tag_dictionary=tag_dictionary,\n",
    "                                        tag_type=tag_type,\n",
    "                                        use_crf=True)\n",
    "    \n",
    "\n",
    "# 6. initialize trainer\n",
    "trainer: SequenceTaggerTrainer = SequenceTaggerTrainer(tagger, corpus)\n",
    "\n",
    "# 7. start training\n",
    "trainer.train(flair_folder,\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
